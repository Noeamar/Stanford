# STABL â€“ Stability-based Feature Selection with Nonlinear Models

## ğŸ“Œ Ã€ propos

**STABL** (Stability-based feature selection with artificial features) est une mÃ©thode de sÃ©lection de variables conÃ§ue pour identifier des ensembles de features stables et interprÃ©tables, mÃªme dans des environnements bruitÃ©s ou de haute dimension.  

Historiquement, STABL sâ€™appuyait sur des modÃ¨les linÃ©aires (Lasso, ElasticNet, ALasso). Cela permet dâ€™obtenir des sÃ©lections trÃ¨s **parcimonieuses et stables**, mais limitÃ©es aux signaux linÃ©aires/monotones.  
Ce projet explore lâ€™extension de STABL avec des **modÃ¨les non linÃ©aires**, notamment **XGBoost**, afin de capturer des interactions, seuils et saturations souvent prÃ©sents dans des donnÃ©es biologiques complexes.

---

## âš™ï¸ Pipeline STABL

Le pipeline gÃ©nÃ©ral se dÃ©roule en deux phases :

### 1. SÃ©lection de variables
- GÃ©nÃ©ration de **N bootstraps** (â‰ˆ 50% des Ã©chantillons par bootstrap).  
- EntraÃ®nement dâ€™un **modÃ¨le de base** sur chaque bootstrap.  
- RÃ©cupÃ©ration des importances de chaque feature.  
- Normalisation ou binarisation des importances.  
- AgrÃ©gation des scores sur lâ€™ensemble des bootstraps.  
- Seuil basÃ© sur **contrÃ´le FDR** et **stabilitÃ©** pour retenir un ensemble final de features.

### 2. RÃ©entraÃ®nement
- Sur les features sÃ©lectionnÃ©es, on ajuste un modÃ¨le final (logistique, linÃ©aire ou non-linÃ©aire selon le cas dâ€™usage).

---

## ğŸš€ Extension : STABL + XGBoost

### Pourquoi XGBoost ?
- Les modÃ¨les linÃ©aires sont efficaces sur signaux monotones.  
- De nombreuses donnÃ©es rÃ©elles prÃ©sentent des **interactions (Xâ‚Ã—Xâ‚‚)**, des **seuils** ou des **saturations**.  
- **XGBoost** comme estimateur de base permet de capturer ces non-linÃ©aritÃ©s tout en conservant le principe de stabilitÃ© de STABL.

### Importances testÃ©es
- `weight` (frÃ©quence dâ€™utilisation dâ€™une feature dans les splits)  
- `gain` (rÃ©duction moyenne de la perte due Ã  la feature)  
- `total_gain` (somme des gains)  
- `cover` (nombre moyen dâ€™Ã©chantillons sÃ©parÃ©s par la feature)  
- `total_cover` (somme des couvertures)  
- `SHAP` (attribution locale puis importance globale via TreeSHAP)

### HyperparamÃ¨tres explorÃ©s
- **Base XGB** pour la sÃ©lection :  
  - `max_depth âˆˆ {3, 6, 9}`  
  - `reg_alpha âˆˆ {0, 0.5, 1, 2, 5}`  
  - `seed=42`, `B=1000 bootstraps`  

- **RÃ©entraÃ®nement final** :  
  - `n_estimators â‰ˆ 200â€“800`  
  - `learning_rate âˆˆ [0.01, 0.1]`  
  - `subsample â‰ˆ 0.6`  
  - `colsample_bytree â‰ˆ 0.5`

---

## ğŸ“Š RÃ©sultats (rÃ©sumÃ© des datasets)

- **Onset of Labor (CyTOF + ProtÃ©omics, regression)**  
  - STABL ElasticNet (linÃ©aire) â†’ baseline  
  - STABL XGBoost â†’ amÃ©lioration sur signaux complexes  

- **COVID-19 (classification)**  
  - Best STABL Linear : Lasso  
  - STABL XGBoost : AUROC = **0.891** (vs 0.830), AUPRC = **0.82** (vs 0.74)  

- **CFRNA (classification)**  
  - Best Linear : Lasso  
  - STABL XGBoost : AUROC = **0.871**, AUPRC = **0.92**  

- **Biobank SSI (classification)**  
  - Best Linear : Lasso  
  - STABL XGBoost : AUROC = **0.828**, AUPRC = **0.51**  

---

## ğŸ“‚ Structure du dÃ©pÃ´t

Stanford/
â”œâ”€â”€ src/             
â”‚   â”œâ”€â”€ stabl_linear/   *ImplÃ©mentations classiques (Lasso, EN, ALasso)*
â”‚   â”œâ”€â”€ stabl_xgb/      *ImplÃ©mentations STABL avec XGBoost*
â”‚   â””â”€â”€ utils/          *Fonctions de support (normalisation, mÃ©triquesâ€¦)*
â”œâ”€â”€ notebooks/          *Notebooks dâ€™expÃ©rimentation et dâ€™analyse*
â”œâ”€â”€ results/            *RÃ©sultats : perfs, features sÃ©lectionnÃ©es, plots*
â”œâ”€â”€ data/               *Jeux de donnÃ©es (non inclus dans le repo public)*
â””â”€â”€ README.md



---

## ğŸ”§ Installation

```bash
# 1. Cloner le repo
git clone https://github.com/Noeamar/Stanford.git
cd Stanford

# 2. CrÃ©er un environnement Python
python3 -m venv venv
source venv/bin/activate

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

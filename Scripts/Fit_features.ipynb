{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a28266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union STABL Lasso & STABL XGBoost: Moyenne=36.7, Médiane=18.0\n",
      "Intersect STABL Lasso & STABL XGBoost: Moyenne=0.4, Médiane=0.0\n",
      "2 → Union STABL Lasso & STABL XGBoost / Intersect STABL Lasso & STABL XGBoost\n",
      "Union STABL Lasso & STABL XGBoost: Moyenne=36.7, Médiane=18.0\n",
      "Intersect STABL Lasso & STABL XGBoost: Moyenne=0.4, Médiane=0.0\n",
      "Union STABL Lasso & STABL ALasso: Moyenne=55.9, Médiane=30.0\n",
      "Intersect STABL Lasso & STABL ALasso: Moyenne=21.9, Médiane=10.0\n",
      "4 → Union STABL Lasso & STABL ALasso / Intersect STABL Lasso & STABL ALasso\n",
      "Union STABL Lasso & STABL XGBoost: Moyenne=36.7, Médiane=18.0\n",
      "Intersect STABL Lasso & STABL XGBoost: Moyenne=0.4, Médiane=0.0\n",
      "Union STABL Lasso & STABL ALasso: Moyenne=55.9, Médiane=30.0\n",
      "Intersect STABL Lasso & STABL ALasso: Moyenne=21.9, Médiane=10.0\n",
      "Union STABL XGBoost & STABL ALasso: Moyenne=41.5, Médiane=19.0\n",
      "Intersect STABL XGBoost & STABL ALasso: Moyenne=0.4, Médiane=0.0\n",
      "6 → Union STABL XGBoost & STABL ALasso / Intersect STABL XGBoost & STABL ALasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV: 100%|██████████| 100/100 [00:03<00:00, 26.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STABL Lasso slide10_P01endoIMC_mgd_UC724_1_4    0.255490\n",
      "slide10_P01endoIMC_mgd_UC724_2_5    0.038612\n",
      "slide10_P01endoIMC_mgd_UC724_3_6    0.139699\n",
      "slide10_P01endoIMC_mgd_UC738_1_1    0.390969\n",
      "slide10_P01endoIMC_mgd_UC738_2_2    0.323937\n",
      "                                      ...   \n",
      "slide8_P01endoIMC_mgd_UC272_2_2     0.259649\n",
      "slide8_P01endoIMC_mgd_UC272_3_3     0.272123\n",
      "slide9_P01endoIMC_mgd_NCB024_1_1    0.518708\n",
      "slide9_P01endoIMC_mgd_NCB024_2_2    0.727690\n",
      "slide9_P01endoIMC_mgd_NCB024_3_3    0.716713\n",
      "Length: 188, dtype: float64\n",
      "STABL XGBoost slide10_P01endoIMC_mgd_UC724_1_4    0.5\n",
      "slide10_P01endoIMC_mgd_UC724_2_5    0.5\n",
      "slide10_P01endoIMC_mgd_UC724_3_6    0.5\n",
      "slide10_P01endoIMC_mgd_UC738_1_1    0.5\n",
      "slide10_P01endoIMC_mgd_UC738_2_2    0.5\n",
      "                                   ... \n",
      "slide8_P01endoIMC_mgd_UC272_2_2     0.5\n",
      "slide8_P01endoIMC_mgd_UC272_3_3     0.5\n",
      "slide9_P01endoIMC_mgd_NCB024_1_1    0.5\n",
      "slide9_P01endoIMC_mgd_NCB024_2_2    0.5\n",
      "slide9_P01endoIMC_mgd_NCB024_3_3    0.5\n",
      "Length: 188, dtype: float64\n",
      "STABL ALasso slide10_P01endoIMC_mgd_UC724_1_4    0.087298\n",
      "slide10_P01endoIMC_mgd_UC724_2_5    0.055903\n",
      "slide10_P01endoIMC_mgd_UC724_3_6    0.084581\n",
      "slide10_P01endoIMC_mgd_UC738_1_1    0.329358\n",
      "slide10_P01endoIMC_mgd_UC738_2_2    0.271883\n",
      "                                      ...   \n",
      "slide8_P01endoIMC_mgd_UC272_2_2     0.290630\n",
      "slide8_P01endoIMC_mgd_UC272_3_3     0.226904\n",
      "slide9_P01endoIMC_mgd_NCB024_1_1    0.422196\n",
      "slide9_P01endoIMC_mgd_NCB024_2_2    0.690983\n",
      "slide9_P01endoIMC_mgd_NCB024_3_3    0.599066\n",
      "Length: 188, dtype: float64\n",
      "Union STABL Lasso & STABL XGBoost slide10_P01endoIMC_mgd_UC724_1_4    0.219897\n",
      "slide10_P01endoIMC_mgd_UC724_2_5    0.027138\n",
      "slide10_P01endoIMC_mgd_UC724_3_6    0.139699\n",
      "slide10_P01endoIMC_mgd_UC738_1_1    0.390969\n",
      "slide10_P01endoIMC_mgd_UC738_2_2    0.323937\n",
      "                                      ...   \n",
      "slide8_P01endoIMC_mgd_UC272_2_2     0.277506\n",
      "slide8_P01endoIMC_mgd_UC272_3_3     0.295339\n",
      "slide9_P01endoIMC_mgd_NCB024_1_1    0.504040\n",
      "slide9_P01endoIMC_mgd_NCB024_2_2    0.742457\n",
      "slide9_P01endoIMC_mgd_NCB024_3_3    0.687542\n",
      "Length: 188, dtype: float64\n",
      "Intersect STABL Lasso & STABL XGBoost slide10_P01endoIMC_mgd_UC724_1_4    0.5\n",
      "slide10_P01endoIMC_mgd_UC724_2_5    0.5\n",
      "slide10_P01endoIMC_mgd_UC724_3_6    0.5\n",
      "slide10_P01endoIMC_mgd_UC738_1_1    0.5\n",
      "slide10_P01endoIMC_mgd_UC738_2_2    0.5\n",
      "                                   ... \n",
      "slide8_P01endoIMC_mgd_UC272_2_2     0.5\n",
      "slide8_P01endoIMC_mgd_UC272_3_3     0.5\n",
      "slide9_P01endoIMC_mgd_NCB024_1_1    0.5\n",
      "slide9_P01endoIMC_mgd_NCB024_2_2    0.5\n",
      "slide9_P01endoIMC_mgd_NCB024_3_3    0.5\n",
      "Length: 188, dtype: float64\n",
      "Union STABL Lasso & STABL ALasso slide10_P01endoIMC_mgd_UC724_1_4    0.219897\n",
      "slide10_P01endoIMC_mgd_UC724_2_5    0.007884\n",
      "slide10_P01endoIMC_mgd_UC724_3_6    0.020808\n",
      "slide10_P01endoIMC_mgd_UC738_1_1    0.339349\n",
      "slide10_P01endoIMC_mgd_UC738_2_2    0.168803\n",
      "                                      ...   \n",
      "slide8_P01endoIMC_mgd_UC272_2_2     0.214810\n",
      "slide8_P01endoIMC_mgd_UC272_3_3     0.186302\n",
      "slide9_P01endoIMC_mgd_NCB024_1_1    0.553838\n",
      "slide9_P01endoIMC_mgd_NCB024_2_2    0.736558\n",
      "slide9_P01endoIMC_mgd_NCB024_3_3    0.899602\n",
      "Length: 188, dtype: float64\n",
      "Intersect STABL Lasso & STABL ALasso slide10_P01endoIMC_mgd_UC724_1_4    0.186606\n",
      "slide10_P01endoIMC_mgd_UC724_2_5    0.108147\n",
      "slide10_P01endoIMC_mgd_UC724_3_6    0.120196\n",
      "slide10_P01endoIMC_mgd_UC738_1_1    0.400905\n",
      "slide10_P01endoIMC_mgd_UC738_2_2    0.413429\n",
      "                                      ...   \n",
      "slide8_P01endoIMC_mgd_UC272_2_2     0.300894\n",
      "slide8_P01endoIMC_mgd_UC272_3_3     0.351616\n",
      "slide9_P01endoIMC_mgd_NCB024_1_1    0.440945\n",
      "slide9_P01endoIMC_mgd_NCB024_2_2    0.606169\n",
      "slide9_P01endoIMC_mgd_NCB024_3_3    0.492665\n",
      "Length: 188, dtype: float64\n",
      "Union STABL XGBoost & STABL ALasso slide10_P01endoIMC_mgd_UC724_1_4    0.051748\n",
      "slide10_P01endoIMC_mgd_UC724_2_5    0.055903\n",
      "slide10_P01endoIMC_mgd_UC724_3_6    0.077517\n",
      "slide10_P01endoIMC_mgd_UC738_1_1    0.377003\n",
      "slide10_P01endoIMC_mgd_UC738_2_2    0.271883\n",
      "                                      ...   \n",
      "slide8_P01endoIMC_mgd_UC272_2_2     0.334956\n",
      "slide8_P01endoIMC_mgd_UC272_3_3     0.259781\n",
      "slide9_P01endoIMC_mgd_NCB024_1_1    0.425948\n",
      "slide9_P01endoIMC_mgd_NCB024_2_2    0.687434\n",
      "slide9_P01endoIMC_mgd_NCB024_3_3    0.628664\n",
      "Length: 188, dtype: float64\n",
      "Intersect STABL XGBoost & STABL ALasso slide10_P01endoIMC_mgd_UC724_1_4    0.5\n",
      "slide10_P01endoIMC_mgd_UC724_2_5    0.5\n",
      "slide10_P01endoIMC_mgd_UC724_3_6    0.5\n",
      "slide10_P01endoIMC_mgd_UC738_1_1    0.5\n",
      "slide10_P01endoIMC_mgd_UC738_2_2    0.5\n",
      "                                   ... \n",
      "slide8_P01endoIMC_mgd_UC272_2_2     0.5\n",
      "slide8_P01endoIMC_mgd_UC272_3_3     0.5\n",
      "slide9_P01endoIMC_mgd_NCB024_1_1    0.5\n",
      "slide9_P01endoIMC_mgd_NCB024_2_2    0.5\n",
      "slide9_P01endoIMC_mgd_NCB024_3_3    0.5\n",
      "Length: 188, dtype: float64\n",
      "→ Terminé, prédictions agrégées renvoyées.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from os.path import join\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit, RepeatedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, ElasticNet\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from stabl.data import load_onset_of_labor, load_ssi\n",
    "from stabl.multi_omic_pipelines import multi_omic_stabl_cv_noe_test\n",
    "\n",
    "# STABL imports\n",
    "from stabl.adaptive import ALasso\n",
    "from stabl.stabl import Stabl\n",
    "from stabl.preprocessing import remove_low_info_samples, LowInfoFilter\n",
    "from stabl.pipelines_utils import compute_scores_table, save_plots\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. Définition des estimateurs STABL\n",
    "# -------------------------------------------------------------------\n",
    "inner_cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=42)\n",
    "lasso  = Lasso(max_iter=int(1e6), random_state=42)\n",
    "en     = ElasticNet(max_iter=int(1e6), random_state=42)\n",
    "alasso = ALasso(max_iter=int(1e6), random_state=42)\n",
    "xgb    = XGBRegressor(random_state=42, importance_type=\"gain\", objective=\"reg:squarederror\")\n",
    "\n",
    "stabl_lasso = Stabl(\n",
    "    base_estimator=lasso, n_bootstraps=1000,\n",
    "    artificial_type=\"knockoff\", artificial_proportion=1.0,\n",
    "    replace=False, fdr_threshold_range=np.arange(0.1,1,0.01),\n",
    "    sample_fraction=0.5, random_state=42,\n",
    "    lambda_grid={\"alpha\": np.logspace(0,2,10)}, verbose=1,\n",
    ")\n",
    "stabl_alasso = clone(stabl_lasso).set_params(base_estimator=alasso)\n",
    "stabl_en     = clone(stabl_lasso).set_params(\n",
    "    base_estimator=en,\n",
    "    lambda_grid={\"alpha\": np.logspace(0.5,2,10), \"l1_ratio\":[0.5,0.7,0.9]}\n",
    ")\n",
    "stabl_xgb    = Stabl(\n",
    "    base_estimator=xgb, n_bootstraps=1000,\n",
    "    artificial_type=\"knockoff\", artificial_proportion=1.0,\n",
    "    replace=False, fdr_threshold_range=np.arange(0.1,1,0.01),\n",
    "    sample_fraction=0.5, random_state=42,\n",
    "    lambda_grid={\"max_depth\":[3,6,9], \"reg_alpha\":[0,0.5,1,2]},\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. Fonction de CV sur features existantes (avec union/intersect)\n",
    "# -------------------------------------------------------------------\n",
    "def cv_on_existing_feats(\n",
    "    data_dict, y, outer_splitter,\n",
    "    estimators, task_type, model_chosen,\n",
    "    models, fold_feats_path, save_path,\n",
    "    outer_groups=None, early_fusion=False,\n",
    "    late_fusion=False, n_iter_lf=10000,\n",
    "    use_ega=False\n",
    "):\n",
    "    logit   = LogisticRegression(max_iter=1000)\n",
    "    linreg  = LinearRegression()\n",
    "    rf_est  = estimators[\"random_forest\"]\n",
    "    xgb_est = estimators[\"xgboost\"]\n",
    "\n",
    "    os.makedirs(Path(save_path, \"Training CV\"), exist_ok=True)\n",
    "    os.makedirs(Path(save_path, \"Summary\"),     exist_ok=True)\n",
    "\n",
    "    X_tot = pd.concat(data_dict.values(), axis=1)\n",
    "    preds_dict   = {m: pd.DataFrame(index=y.index) for m in models}\n",
    "    feats_dict   = {m: [] for m in models}\n",
    "\n",
    "    # Lecture des sélections STABL originales\n",
    "    raw_sel = {}\n",
    "    for m in models:\n",
    "        if m.startswith(\"STABL \"):\n",
    "            df = pd.read_csv(Path(fold_feats_path,\"Training CV\",f\"Selected Features {m}.csv\"), index_col=0)\n",
    "            raw_sel[m] = [\n",
    "                eval(s) if isinstance(s,str) else s\n",
    "                for s in df[\"Fold selected features\"]\n",
    "            ]\n",
    "\n",
    "    n_splits = outer_splitter.get_n_splits(X=X_tot, y=y, groups=outer_groups)\n",
    "\n",
    "    for fold_idx, (train_i, test_i) in enumerate(tqdm(\n",
    "        outer_splitter.split(X_tot, y, groups=outer_groups),\n",
    "        total=n_splits, desc=\"Outer CV\"\n",
    "    )):\n",
    "        train_ids = y.iloc[train_i].index\n",
    "        test_ids  = y.iloc[test_i].index\n",
    "\n",
    "        # On récupère pour chaque modèle la liste de features\n",
    "        for m in models:\n",
    "            if m.startswith(\"Union \"):\n",
    "                # \"Union STABL Lasso & STABL ALasso\" → ['STABL Lasso','STABL ALasso']\n",
    "                bases = m.replace(\"Union \",\"\").split(\" & \")\n",
    "                sets  = [ set(raw_sel[b][fold_idx]) for b in bases ]\n",
    "                feats = list(set.union(*sets))\n",
    "            elif m.startswith(\"Intersect \"):\n",
    "                bases = m.replace(\"Intersect \",\"\").split(\" & \")\n",
    "                sets  = [ set(raw_sel[b][fold_idx]) for b in bases ]\n",
    "                feats = list(set.intersection(*sets))\n",
    "            elif m.startswith(\"STABL \"):\n",
    "                feats = raw_sel[m][fold_idx]\n",
    "            else:\n",
    "                # non-STABL → on peut choisir all‑features ou fallback\n",
    "                feats = list(X_tot.columns)\n",
    "\n",
    "            # Fit / predict\n",
    "            if len(feats)==0:\n",
    "                val = (0.5 if task_type==\"binary\" else np.mean(y.loc[train_ids]))\n",
    "                preds_dict[m].loc[test_ids, f\"Fold_{fold_idx}\"] = val\n",
    "            else:\n",
    "                pipe = Pipeline([\n",
    "                    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                    (\"scaler\",  StandardScaler())\n",
    "                ])\n",
    "                Xtr = pd.DataFrame(pipe.fit_transform(X_tot.loc[train_ids, feats]),\n",
    "                                   index=train_ids, columns=feats)\n",
    "                Xte = pd.DataFrame(pipe.transform(X_tot.loc[test_ids, feats]),\n",
    "                                   index=test_ids,  columns=feats)\n",
    "\n",
    "                key = (model_chosen or \"logit\").lower()\n",
    "\n",
    "                if task_type == \"binary\":\n",
    "                    est = {\"xgboost\": xgb_est, \"random_forest\": rf_est, \"logit\": logit}.get(model_chosen, logit)\n",
    "                    pr  = clone(est).fit(Xtr, y.loc[train_ids]).predict_proba(Xte)[:, 1]\n",
    "                else:\n",
    "                    est = {\"xgboost\": xgb_est, \"random_forest\": rf_est}.get(model_chosen, linreg)\n",
    "                    pr  = clone(est).fit(Xtr, y.loc[train_ids]).predict(Xte)\n",
    "\n",
    "                preds_dict[m].loc[test_ids, f\"Fold_{fold_idx}\"] = pr\n",
    "\n",
    "            feats_dict[m].append(feats)\n",
    "\n",
    "    # Sauvegarde des listes\n",
    "    cv_dir = Path(save_path,\"Training CV\")\n",
    "    for m in models:\n",
    "        dfm = pd.DataFrame({\n",
    "            \"Fold selected features\": feats_dict[m],\n",
    "            \"Fold #features\": [len(f) for f in feats_dict[m]]\n",
    "        }, index=[f\"Fold_{i}\" for i in range(n_splits)])\n",
    "        dfm.to_csv(cv_dir/f\"Selected Features {m}.csv\")\n",
    "\n",
    "    # Scores & plots\n",
    "    summary_dir = Path(save_path,\"Summary\")\n",
    "    med_preds = {m: preds_dict[m].median(axis=1) for m in models}\n",
    "    scores = compute_scores_table(\n",
    "        predictions_dict=med_preds,\n",
    "        y=y,\n",
    "        task_type=task_type,\n",
    "        selected_features_dict=None\n",
    "    )\n",
    "    scores.to_csv(summary_dir / \"Scores_training_CV.csv\")\n",
    "    save_plots(\n",
    "        predictions_dict=med_preds,\n",
    "        y=y,\n",
    "        task_type=task_type,\n",
    "        save_path=cv_dir\n",
    "     )\n",
    "\n",
    "    return med_preds\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Point d'entrée\n",
    "# -------------------------------------------------------------------\n",
    "if __name__==\"__main__\":\n",
    "    # 3.1 \n",
    "    X_PATH     = Path(\"/Users/noeamar/Documents/Stanford/data/olivier_data/ina_13OG_final_long_allstims_filtered (6).csv\")\n",
    "    Y_PATH     = Path(\"/Users/noeamar/Documents/Stanford/data/olivier_data/outcome_table_all_pre.csv\")\n",
    "    FOLD_FEATS = Path(\"/Users/noeamar/Documents/Stanford/Sherlock Results/Maigane/results_maigane_normalized_001_omics/control_vs_severe/MAIGANE_control_vs_severe_Functional_xgboost_knockoff_total_cover_GSS/Functional\")\n",
    "    SAVE_ROOT  = Path(\"/Users/noeamar/Documents/Stanford/Fitting results/Maigane data/Control_vs_severe/Functional KO_total_cover + Logit\")\n",
    " \n",
    "    # # Load INA\n",
    "    # X = pd.read_csv(X_PATH, index_col=0)\n",
    "    # y = pd.read_csv(Y_PATH, index_col=0).squeeze()\n",
    "    # common = X.index.intersection(y.index)\n",
    "    # X, y = X.loc[common], y.loc[common]\n",
    "\n",
    "    # # # 3.2 Splitter & data_dict\n",
    "    # task_type = \"regression\"\n",
    "    # groups   = X.index.to_series().str.split(\"_\").str[0]\n",
    "    # splitter = GroupShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "    # data_dict= {\"allstim\": X}\n",
    "\n",
    "    # # 1) Load OOL\n",
    "    # train_dict, valid_data_dict, y, y_valid, patients_id, task_type = load_onset_of_labor(\n",
    "    # \"/Users/noeamar/Documents/Stanford/data/Onset of Labor\"\n",
    "    # )\n",
    "\n",
    "    # cyto_train = train_dict[\"CyTOF\"]\n",
    "    # prot_train = train_dict[\"Proteomics\"].copy()\n",
    "    # # Préfixe PRO_ pour distinguer les colonnes\n",
    "    # prot_train.columns = [f\"{c}\" for c in prot_train.columns]\n",
    "\n",
    "    # # 2) Intersection des index sur (y, cyto, prot)\n",
    "    # common = y.index\n",
    "    # for df in (cyto_train, prot_train):\n",
    "    #     common = common.intersection(df.index)\n",
    "\n",
    "    # y = y.loc[common]\n",
    "    # cyto_train = cyto_train.loc[common]\n",
    "    # prot_train = prot_train.loc[common]\n",
    "\n",
    "    # # 3) Early-fusion: un seul X\n",
    "    # X = pd.concat([cyto_train, prot_train], axis=1)\n",
    "\n",
    "    # # 4) Splitter & data_dict (un seul bloc \"allstim\")\n",
    "    # groups   = X.index.to_series().str.split(\"_\").str[0]\n",
    "    # splitter = GroupShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "    # data_dict = {\"allstim\": X}\n",
    "\n",
    "    # # Load SSI\n",
    "    # train_data_dict, _, y, _, _, task_type = load_ssi(\"/Users/noeamar/Documents/Stanford/data/Biobank SSI\")  # task_type = \"binary\"\n",
    "    \n",
    "    # # Assainir les labels\n",
    "    # # y = y.astype(int)\n",
    "    # # vals = sorted(set(y.unique()))\n",
    "    # # print(\"Labels uniques:\", vals)  # doit afficher [0, 1]\n",
    "    # # assert set(vals) <= {0, 1}\n",
    "\n",
    "    # # # 3) Early-fusion: concat CyTOF + Proteomics en un seul X\n",
    "    # cyto = train_data_dict[\"CyTOF\"]\n",
    "    # prot = train_data_dict[\"Proteomics\"].copy()\n",
    "    # # print(\"Taille de CyTOF :\", cyto.shape)\n",
    "    # # print(\"Taille de Proteomics :\", prot.shape)\n",
    "    # # (Option recommandé) Préfixer la protéomique pour éviter toute collision de noms :\n",
    "    # prot.columns = [f\"PRO_{c}\" for c in prot.columns]\n",
    "\n",
    "    # # 4) Aligner les index sur l’intersection commune (y, cyto, prot)\n",
    "    # common = y.index\n",
    "    # for df in (cyto, prot):\n",
    "    #     common = common.intersection(df.index)\n",
    "\n",
    "    # y = y.loc[common]\n",
    "    # X = pd.concat([cyto.loc[common], prot.loc[common]], axis=1)\n",
    "\n",
    "    # X=pd.concat([cyto, prot], axis=1)\n",
    "    # print(\"Taille de X :\", X.shape)\n",
    "    # print(\"Taille de y :\", y.shape)\n",
    "\n",
    "    # print(\"\\n--- VERSION INTERSECTION COMMUNE ---\")\n",
    "\n",
    "    # # Index de départ\n",
    "    # print(\"Index y :\", y.index.tolist())\n",
    "    # print(\"Index cyto :\", cyto.index.tolist())\n",
    "    # print(\"Index prot :\", prot.index.tolist())\n",
    "\n",
    "    # # Intersection progressive\n",
    "    # common = y.index\n",
    "    # print(\"\\nÉtape 0 - common (y.index) :\", common.tolist())\n",
    "\n",
    "    # for i, df in enumerate((cyto, prot), start=1):\n",
    "    #     common = common.intersection(df.index)\n",
    "    #     print(f\"Étape {i} - intersection avec df{i} :\", common.tolist())\n",
    "\n",
    "    # # Sélection finale\n",
    "    # y_common = y.loc[common]\n",
    "    # X_common = pd.concat([cyto.loc[common], prot.loc[common]], axis=1)\n",
    "\n",
    "    # print(\"\\nTaille finale y_common :\", y_common.shape)\n",
    "    # print(\"Taille finale X_common :\", X_common.shape)\n",
    "    # print(\"Index final commun :\", common.tolist())\n",
    "\n",
    "    # # Exemple de premières lignes\n",
    "    # print(\"\\nAperçu X_common :\")\n",
    "    # print(X_common.head())\n",
    "\n",
    "    # # ------------------------\n",
    "    # print(\"\\n--- VERSION CONCAT SIMPLE ---\")\n",
    "    # X_simple = pd.concat([cyto, prot], axis=1)\n",
    "\n",
    "    # print(\"Taille X_simple :\", X_simple.shape)\n",
    "    # print(\"Index X_simple :\", X_simple.index.tolist())\n",
    "\n",
    "    # # Vérification des NaN éventuels\n",
    "    # nan_counts = X_simple.isna().sum().sum()\n",
    "    # print(\"Nombre total de NaN dans X_simple :\", nan_counts)\n",
    "\n",
    "    # # Option) S’assurer que y est bien 0/1\n",
    "    # y = y.astype(int)\n",
    "\n",
    "    # # 5) Splitter & data_dict (identique à ton snippet)\n",
    "    # groups   = X_simple.index.to_series().str.split(\"_\").str[0]\n",
    "    # #splitter = GroupShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "    # splitter=RepeatedStratifiedKFold(n_splits=5, n_repeats=20, random_state=42)\n",
    "    # data_dict = {\"allstim\": X_simple}\n",
    "\n",
    "    # # Load COVID-19\n",
    "    # from stabl.data import load_covid_19\n",
    "    # X_train, X_valid, y_train, y_valid, ids, task_type = load_covid_19(\"/Users/noeamar/Documents/Stanford/data/COVID-19\")\n",
    "    # # Assainir les labels\n",
    "    # y_train = y_train.astype(int)\n",
    "    # y_valid = y_valid.astype(int)\n",
    "    # vals = sorted(set(y_valid.unique()))\n",
    "    # print(\"Labels uniques:\", vals)  # doit afficher [0, 1]\n",
    "    # assert set(vals) <= {0, 1} \n",
    "    # data_dict = X_valid\n",
    "    # # If X_valid is a dict, print the shape of each DataFrame inside\n",
    "    # if isinstance(X_valid, dict):\n",
    "    #     for k, v in X_valid.items():\n",
    "    #         print(f\"X_valid[{k}] shape:\", v.shape)\n",
    "    # else:\n",
    "    #     print(\"X_valid shape:\", X_valid.shape)\n",
    "\n",
    "    # if isinstance(X_train, dict):\n",
    "    #     for k, v in X_valid.items():\n",
    "    #         print(f\"X_train[{k}] shape:\", v.shape)\n",
    "    # else:\n",
    "    #     print(\"X_train shape:\", X_valid.shape)\n",
    "    # splitter = RepeatedStratifiedKFold(n_splits=5, n_repeats=20, random_state=42)\n",
    "    # y= y_valid\n",
    "    # groups = ids\n",
    "\n",
    "    # Load CFRNA\n",
    "    # from stabl.data import load_cfrna\n",
    "    # data_dict, valid_data_dict, y, y_valid, groups, task_type = load_cfrna(\"/Users/noeamar/Documents/Stanford/data/CFRNA\")\n",
    "    # # Assainir les labels\n",
    "    # y = y.astype(int)\n",
    "    # vals = sorted(set(y.unique()))\n",
    "    # print(\"Labels uniques:\", vals)  # doit afficher [0, 1]\n",
    "    # assert set(vals) <= {0, 1}\n",
    "\n",
    "    #splitter  = GroupShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Load Maigane dataset\n",
    "\n",
    "    def load_maigane(data_path, label_mode=\"control_vs_em\", miss_thresh=0.99):\n",
    "        \"\"\"\n",
    "        Charge et préprocess MAIGANE puis renvoie:\n",
    "        (X_dict, None, y, None, groups, \"binary\")\n",
    "\n",
    "        Paramètres\n",
    "        ----------\n",
    "        data_path : str\n",
    "            Dossier contenant les CSV (e.g. \".../Maigane data\")\n",
    "        label_mode : {\"control_vs_em\",\"control_vs_mild\",\"control_vs_severe\",\"mild_vs_severe\"}\n",
    "            - \"control_vs_em\"      : Control (0) vs EM (1) via ControlVsEM.csv\n",
    "            - \"control_vs_mild\"    : Control (0) vs I&II (1)\n",
    "            - \"control_vs_severe\"  : Control (0) vs III&IV (1)\n",
    "            - \"mild_vs_severe\"     : I&II (0) vs III&IV (1)\n",
    "        miss_thresh : float ∈ (0,1]\n",
    "            Seuil max de fraction de NaN autorisée par colonne (par défaut 0.99)\n",
    "        \"\"\"\n",
    "        import re\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        from os.path import join\n",
    "\n",
    "        # -------- helpers --------\n",
    "        def _sanitize_cols(cols):\n",
    "            def clean(c):\n",
    "                s = str(c).strip().strip('\"').strip(\"'\")\n",
    "                s = re.sub(r'[\\\\/:*?\"<>|]+', '_', s)   # caractères interdits → _\n",
    "                s = re.sub(r'\\s+', '_', s)            # espaces multiples → _\n",
    "                s = re.sub(r'_+', '_', s)             # __ → _\n",
    "                if s == '' or s.lower().startswith('unnamed'):\n",
    "                    s = 'feature'\n",
    "                return s\n",
    "            cleaned = [clean(c) for c in cols]\n",
    "            # déduplication stable\n",
    "            seen, uniq = {}, []\n",
    "            for s in cleaned:\n",
    "                if s in seen:\n",
    "                    uniq.append(f\"{s}__{seen[s]}\")\n",
    "                    seen[s] += 1\n",
    "                else:\n",
    "                    uniq.append(s)\n",
    "                    seen[s] = 1\n",
    "            return uniq\n",
    "\n",
    "        def _read_omic(path):\n",
    "            # lecture tolérante (auto-sep), pas de low_memory avec engine=\"python\"\n",
    "            df0 = pd.read_csv(path, engine=\"python\", sep=None,\n",
    "                            na_values=[\"NA\", \"NaN\", \"\"], keep_default_na=True)\n",
    "            first = df0.columns[0]\n",
    "            cond_unnamed = first in (\"\", \" \", \"Unnamed: 0\", \"Unnamed: 0.1\", \"Unnamed: 1\")\n",
    "            cond_slide   = df0[first].astype(str).str.startswith(\"slide\").any()\n",
    "\n",
    "            if cond_unnamed or cond_slide:\n",
    "                df = df0.set_index(first)\n",
    "            else:\n",
    "                df = pd.read_csv(path, engine=\"python\", sep=None,\n",
    "                                na_values=[\"NA\", \"NaN\", \"\"], keep_default_na=True,\n",
    "                                index_col=0)\n",
    "\n",
    "            # nettoie index\n",
    "            idx = pd.Index(df.index).astype(str).str.strip().str.strip('\"').str.strip(\"'\")\n",
    "            df.index = idx\n",
    "            df = df[~df.index.duplicated(keep=\"first\")]\n",
    "\n",
    "            # sanitise colonnes\n",
    "            df.columns = _sanitize_cols(df.columns)\n",
    "\n",
    "            # conserve numérique uniquement\n",
    "            df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "            # remplace inf\n",
    "            df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "            # filtre colonnes trop manquantes\n",
    "            if len(df) > 0:\n",
    "                frac_nan = df.isna().mean(axis=0)\n",
    "                keep = frac_nan[frac_nan <= miss_thresh].index\n",
    "                df = df[keep]\n",
    "\n",
    "            # drop 100% NaN\n",
    "            df = df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "            # drop variance nulle (en ignorant NaN)\n",
    "            if df.shape[1] > 0:\n",
    "                var = df.var(axis=0, ddof=1, numeric_only=True)\n",
    "                df = df.loc[:, var > 0]\n",
    "\n",
    "            return df\n",
    "\n",
    "        # -------- labels sources --------\n",
    "        # Control vs EM\n",
    "        y1 = pd.read_csv(join(data_path, \"ControlVsEM.csv\"),\n",
    "                        na_values=[\"NA\", \"NaN\", \"\"], keep_default_na=True)\n",
    "        if \"sampleID\" not in y1.columns or \"EM\" not in y1.columns:\n",
    "            raise ValueError(\"ControlVsEM.csv doit contenir les colonnes 'sampleID' et 'EM'.\")\n",
    "        y1 = y1.set_index(\"sampleID\")[\"EM\"]\n",
    "        if y1.dtype.kind not in \"iu\":\n",
    "            y1 = y1.map({\"Control\": 0, \"EM\": 1})\n",
    "        y1 = y1.astype(\"Int64\")\n",
    "        y1.index = pd.Index(y1.index).astype(str).str.strip().str.strip('\"').str.strip(\"'\")\n",
    "\n",
    "        # Stage I&II vs III&IV (uniquement EM)\n",
    "        y2 = pd.read_csv(join(data_path, \"StageI&IIVsStageIII&IV.csv\"),\n",
    "                        na_values=[\"NA\", \"NaN\", \"\"], keep_default_na=True)\n",
    "        if \"sampleID\" in y2.columns:\n",
    "            y2 = y2.set_index(\"sampleID\")\n",
    "        if \"Stage\" not in y2.columns:\n",
    "            raise ValueError(\"StageI&IIVsStageIII&IV.csv doit contenir la colonne 'Stage'.\")\n",
    "        y2 = y2[\"Stage\"]\n",
    "        if y2.dtype.kind not in \"iu\":\n",
    "            y2 = y2.map({\"I&II\": 0, \"III&IV\": 1})\n",
    "        y2 = y2.astype(\"Int64\")\n",
    "        y2.index = pd.Index(y2.index).astype(str).str.strip().str.strip('\"').str.strip(\"'\")\n",
    "\n",
    "        # -------- construire y selon label_mode --------\n",
    "        mode = label_mode.lower()\n",
    "        if mode == \"control_vs_em\":\n",
    "            # simple binaire Control(0) vs EM(1)\n",
    "            y = y1.dropna().astype(int)\n",
    "\n",
    "        elif mode == \"control_vs_mild\":\n",
    "            # Control(0) vs I&II(1)\n",
    "            idx = sorted(set(y1.index[y1 == 0]).union(set(y2.index[y2 == 0])))\n",
    "            y = pd.Series(pd.NA, index=idx, dtype=\"Int64\")\n",
    "            y.loc[y1.index[y1 == 0]] = 0\n",
    "            y.loc[y2.index[y2 == 0]] = 1\n",
    "            y = y.dropna().astype(int)\n",
    "\n",
    "        elif mode == \"control_vs_severe\":\n",
    "            # Control(0) vs III&IV(1)\n",
    "            idx = sorted(set(y1.index[y1 == 0]).union(set(y2.index[y2 == 1])))\n",
    "            y = pd.Series(pd.NA, index=idx, dtype=\"Int64\")\n",
    "            y.loc[y1.index[y1 == 0]] = 0\n",
    "            y.loc[y2.index[y2 == 1]] = 1\n",
    "            y = y.dropna().astype(int)\n",
    "\n",
    "        elif mode == \"mild_vs_severe\":\n",
    "            # I&II(0) vs III&IV(1) sur patients EM\n",
    "            y = y2.dropna().astype(int)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"label_mode inconnu. Utilise l'un de : \"\n",
    "                \"'control_vs_em', 'control_vs_mild', 'control_vs_severe', 'mild_vs_severe'.\"\n",
    "            )\n",
    "\n",
    "        # -------- omiques --------\n",
    "        file_map = {\n",
    "            \"CellDensities\": \"EMIMCmdiop_celldensities.csv\",\n",
    "            \"Functional\":    \"EMIMCmdiop_functional.csv\",\n",
    "            \"Metavariables\": \"EMIMCmdiop_metavariables.csv\",\n",
    "            \"Neighborhood\":  \"EMIMCmdiop_neighborhood.csv\",\n",
    "        }\n",
    "        X = {k: _read_omic(join(data_path, fname)) for k, fname in file_map.items()}\n",
    "\n",
    "        # -------- alignement IDs --------\n",
    "        common = pd.Index(y.index)\n",
    "        for df in X.values():\n",
    "            common = common.intersection(df.index)\n",
    "        if common.empty:\n",
    "            raise ValueError(\"Aucun échantillon commun entre omiques et y.\")\n",
    "        y = y.loc[common]\n",
    "        X = {k: df.loc[common] for k, df in X.items()}\n",
    "\n",
    "        # -------- groups robustes depuis l'ID --------\n",
    "        def _extract_group(e: str):\n",
    "            parts = re.split(r'[_\\s]+', e)\n",
    "            return parts[3] if len(parts) > 3 else parts[-1]\n",
    "\n",
    "        groups = pd.Series({_id: _extract_group(_id) for _id in y.index})\n",
    "\n",
    "        return X, None, y, None, groups, \"binary\"\n",
    "\n",
    "\n",
    "    data_dict, _, y, _, groups, task_type = load_maigane(\"./data/Maigane data\", label_mode=\"control_vs_severe\")\n",
    "    \n",
    "    splitter = GroupShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 3.3 Liste initiale de modèles STABL\n",
    "    stabl_models = [\"STABL Lasso\", \"STABL XGBoost\", \"STABL ALasso\"]\n",
    "    #stabl_models = [\"STABL XGBoost\"]\n",
    "    base_models  = stabl_models\n",
    "\n",
    "    xgb_param_grid = {\n",
    "    \"n_estimators\": [170],\n",
    "    \"learning_rate\": [0.005],\n",
    "    \"max_depth\": [6],\n",
    "    \"subsample\": [1],\n",
    "    \"colsample_bytree\": [1]\n",
    "    }\n",
    "\n",
    "    rf_reg = RandomForestRegressor(n_estimators=600, max_depth=8, min_samples_split=2, min_samples_leaf=2, max_features=\"sqrt\", ccp_alpha=1e-3, random_state=42, n_jobs=-1)\n",
    "    xgb_reg = XGBRegressor(n_estimators=800, learning_rate=0.01, max_depth=3, subsample=0.6, colsample_bytree=0.5 ,random_state=42, n_jobs=-1)\n",
    "    xgb_test_reg = XGBRegressor(n_jobs=-1)\n",
    "    linreg  = LinearRegression(fit_intercept=True, copy_X=False, positive=True, n_jobs=-1)\n",
    "    rf_cls = RandomForestClassifier(n_estimators=600, max_depth=8, min_samples_split=2, min_samples_leaf=2, max_features=\"sqrt\", ccp_alpha=1e-3, random_state=42, n_jobs=-1)\n",
    "    xgb_cls = XGBClassifier(n_estimators=800, learning_rate=0.01, max_depth=3, subsample=0.6, colsample_bytree=0.5 ,random_state=42, n_jobs=-1)\n",
    "    Logit = LogisticRegression(penalty=None, class_weight=\"balanced\", max_iter=int(1e6), random_state=42)\n",
    "    xgb_test =XGBClassifier(n_estimators=200, importance_type=\"gain\", n_jobs=-1)\n",
    "    xgb_test2= XGBClassifier(n_estimators=300, max_depth=4, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8, reg_alpha=0.0, reg_lambda=1.0, eval_metric=\"auc\", n_jobs=-1, random_state=42)\n",
    "    #xgb_grid = GridSearchCV(estimator=xgb_cls, param_grid=xgb_param_grid, cv=inner_cv, scoring=\"roc_auc\", n_jobs=-1, verbose=2, refit=True)\n",
    "    # 3.4 Génération autom. des combos 2‑à‑2 et 3‑à‑3\n",
    "    combos = []\n",
    "    for r in [2]:\n",
    "        for group in itertools.combinations(stabl_models, r):\n",
    "            sep = \" & \"\n",
    "            combos += [f\"Union {sep.join(group)}\", f\"Intersect {sep.join(group)}\"]\n",
    "            # Calcul du nombre de features pour chaque combo\n",
    "            # Calcul du nombre de features pour chaque combo, par fold\n",
    "            for combo in combos:\n",
    "                bases = combo.replace(\"Union \", \"\").replace(\"Intersect \", \"\").split(sep)\n",
    "                # Lecture des features sélectionnés pour chaque modèle de base, par fold\n",
    "                fold_feats = []\n",
    "                for b in bases:\n",
    "                    df = pd.read_csv(Path(FOLD_FEATS, \"Training CV\", f\"Selected Features {b}.csv\"), index_col=0)\n",
    "                    # Chaque ligne = liste de features pour le fold\n",
    "                    fold_feats.append(df[\"Fold selected features\"].apply(eval))\n",
    "                # Calcul union/intersection par fold\n",
    "                fold_counts = []\n",
    "                for fold_idx in range(len(fold_feats[0])):\n",
    "                    sets_fold = [set(f[fold_idx]) if isinstance(f[fold_idx], (list, set)) else set() for f in fold_feats]\n",
    "                    if combo.startswith(\"Union \"):\n",
    "                        feats_fold = set.union(*sets_fold)\n",
    "                    else:\n",
    "                        feats_fold = set.intersection(*sets_fold)\n",
    "                    fold_counts.append(len(feats_fold))\n",
    "                print(f\"{combo}: Moyenne={np.mean(fold_counts):.1f}, Médiane={np.median(fold_counts):.1f}\")\n",
    "            print(len(combos), f\"→ {combos[-2]} / {combos[-1]}\")\n",
    "\n",
    "    models = base_models + combos\n",
    "\n",
    "    # 3.5 Estimateurs à passer\n",
    "    estimators = {\n",
    "        \"Logit\" : Logit,\n",
    "        \"random_forest\": rf_cls,\n",
    "        \"xgboost\":       xgb_cls,\n",
    "        \"stabl_alasso\":  stabl_alasso,\n",
    "        \"stabl_en\":      stabl_en,\n",
    "        \"linreg\":      linreg,\n",
    "        \n",
    "    }\n",
    "\n",
    "    # 3.6 Lancement\n",
    "    preds = cv_on_existing_feats(\n",
    "        data_dict       = data_dict,\n",
    "        y               = y,\n",
    "        outer_splitter  = splitter,\n",
    "        estimators      = estimators,\n",
    "        task_type       = task_type,\n",
    "        model_chosen    = \"Logit\",  # Choix du modèle de base pour les non-STABL\n",
    "        models          = models,\n",
    "        fold_feats_path = FOLD_FEATS,\n",
    "        save_path       = SAVE_ROOT,\n",
    "        outer_groups    = groups,\n",
    "    )\n",
    "\n",
    "    print(\"→ Terminé, prédictions agrégées renvoyées.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be799462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noeamar/Documents/Stanford/stablVMax/stabl/multi_omic_pipelines.py:3: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (91, 1846) | y: (91,) | task_type: binary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unstim_Baso_149Sm_CREB</th>\n",
       "      <th>unstim_Baso_150Nd_STAT5</th>\n",
       "      <th>unstim_Baso_151Eu_p38</th>\n",
       "      <th>unstim_Baso_153Eu_STAT1</th>\n",
       "      <th>unstim_Baso_154Sm_STAT3</th>\n",
       "      <th>unstim_Baso_155Gd_S6</th>\n",
       "      <th>unstim_Baso_159Tb_MAPKAPK2</th>\n",
       "      <th>unstim_Baso_164Dy_IkB</th>\n",
       "      <th>unstim_Baso_166Er_NFkB</th>\n",
       "      <th>unstim_Baso_167Er_ERK</th>\n",
       "      <th>...</th>\n",
       "      <th>PRO_SAT1</th>\n",
       "      <th>PRO_NFKB1</th>\n",
       "      <th>PRO_CDKN2B</th>\n",
       "      <th>PRO_RAP2A</th>\n",
       "      <th>PRO_XRCC4</th>\n",
       "      <th>PRO_ARID1A</th>\n",
       "      <th>PRO_EGLN1</th>\n",
       "      <th>PRO_TOPBP1</th>\n",
       "      <th>PRO_SLC22A16</th>\n",
       "      <th>PRO_IRF6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampleID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BBCR0002</th>\n",
       "      <td>0.632924</td>\n",
       "      <td>0.344065</td>\n",
       "      <td>0.028052</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.143817</td>\n",
       "      <td>0.150393</td>\n",
       "      <td>0.801140</td>\n",
       "      <td>0.681250</td>\n",
       "      <td>0.031901</td>\n",
       "      <td>...</td>\n",
       "      <td>9.571184</td>\n",
       "      <td>11.314243</td>\n",
       "      <td>10.127736</td>\n",
       "      <td>9.873905</td>\n",
       "      <td>8.623150</td>\n",
       "      <td>9.615262</td>\n",
       "      <td>10.399064</td>\n",
       "      <td>8.828454</td>\n",
       "      <td>12.143543</td>\n",
       "      <td>11.980247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBCR0003</th>\n",
       "      <td>0.921823</td>\n",
       "      <td>0.677804</td>\n",
       "      <td>0.041205</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>1.614141</td>\n",
       "      <td>0.138246</td>\n",
       "      <td>0.966064</td>\n",
       "      <td>0.562168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.349171</td>\n",
       "      <td>13.429106</td>\n",
       "      <td>9.698531</td>\n",
       "      <td>9.763378</td>\n",
       "      <td>8.799929</td>\n",
       "      <td>9.465362</td>\n",
       "      <td>10.176298</td>\n",
       "      <td>8.386294</td>\n",
       "      <td>12.561980</td>\n",
       "      <td>11.355186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1846 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          unstim_Baso_149Sm_CREB  unstim_Baso_150Nd_STAT5  \\\n",
       "sampleID                                                    \n",
       "BBCR0002                0.632924                 0.344065   \n",
       "BBCR0003                0.921823                 0.677804   \n",
       "\n",
       "          unstim_Baso_151Eu_p38  unstim_Baso_153Eu_STAT1  \\\n",
       "sampleID                                                   \n",
       "BBCR0002               0.028052                        0   \n",
       "BBCR0003               0.041205                        0   \n",
       "\n",
       "          unstim_Baso_154Sm_STAT3  unstim_Baso_155Gd_S6  \\\n",
       "sampleID                                                  \n",
       "BBCR0002                 0.000000              1.143817   \n",
       "BBCR0003                 0.000672              1.614141   \n",
       "\n",
       "          unstim_Baso_159Tb_MAPKAPK2  unstim_Baso_164Dy_IkB  \\\n",
       "sampleID                                                      \n",
       "BBCR0002                    0.150393               0.801140   \n",
       "BBCR0003                    0.138246               0.966064   \n",
       "\n",
       "          unstim_Baso_166Er_NFkB  unstim_Baso_167Er_ERK  ...  PRO_SAT1  \\\n",
       "sampleID                                                 ...             \n",
       "BBCR0002                0.681250               0.031901  ...  9.571184   \n",
       "BBCR0003                0.562168               0.000000  ...  9.349171   \n",
       "\n",
       "          PRO_NFKB1  PRO_CDKN2B  PRO_RAP2A  PRO_XRCC4  PRO_ARID1A  PRO_EGLN1  \\\n",
       "sampleID                                                                       \n",
       "BBCR0002  11.314243   10.127736   9.873905   8.623150    9.615262  10.399064   \n",
       "BBCR0003  13.429106    9.698531   9.763378   8.799929    9.465362  10.176298   \n",
       "\n",
       "          PRO_TOPBP1  PRO_SLC22A16   PRO_IRF6  \n",
       "sampleID                                       \n",
       "BBCR0002    8.828454     12.143543  11.980247  \n",
       "BBCR0003    8.386294     12.561980  11.355186  \n",
       "\n",
       "[2 rows x 1846 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model1b\n",
       "0    75\n",
       "1    16\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models utilisés : ['STABL Lasso', 'STABL ElasticNet', 'STABL ALasso', 'STABL XGBoost']\n",
      "Estimators ready.\n",
      "[INFO] Starting CV with skip-selection (using existing STABL features)...\n",
      "72 train samples, 19 test samples:   0%|          | 0/100 [00:00<?, ?it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 28 features selected for STABL Lasso\n",
      "This fold: 108 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 10 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   1%|          | 1/100 [00:00<00:18,  5.38it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 37 features selected for STABL Lasso\n",
      "This fold: 51 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 14 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   2%|▏         | 2/100 [00:00<00:16,  6.12it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 23 features selected for STABL Lasso\n",
      "This fold: 109 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   3%|▎         | 3/100 [00:00<00:18,  5.22it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 57 features selected for STABL Lasso\n",
      "This fold: 191 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   4%|▍         | 4/100 [00:00<00:18,  5.23it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 27 features selected for STABL Lasso\n",
      "This fold: 370 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 13 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   5%|▌         | 5/100 [00:01<00:20,  4.67it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 30 features selected for STABL Lasso\n",
      "This fold: 66 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 14 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   6%|▌         | 6/100 [00:01<00:17,  5.30it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 72 features selected for STABL Lasso\n",
      "This fold: 165 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 2 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   7%|▋         | 7/100 [00:01<00:17,  5.24it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 26 features selected for STABL Lasso\n",
      "This fold: 28 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 12 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   8%|▊         | 8/100 [00:01<00:15,  5.81it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 25 features selected for STABL Lasso\n",
      "This fold: 321 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   9%|▉         | 9/100 [00:01<00:17,  5.07it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 30 features selected for STABL Lasso\n",
      "This fold: 237 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 12 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  10%|█         | 10/100 [00:01<00:18,  4.95it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 44 features selected for STABL Lasso\n",
      "This fold: 117 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 12 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  11%|█         | 11/100 [00:02<00:17,  5.16it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 38 features selected for STABL Lasso\n",
      "This fold: 41 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 15 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  12%|█▏        | 12/100 [00:02<00:15,  5.80it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 49 features selected for STABL Lasso\n",
      "This fold: 156 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 16 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  13%|█▎        | 13/100 [00:02<00:15,  5.70it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 31 features selected for STABL Lasso\n",
      "This fold: 15 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 11 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  14%|█▍        | 14/100 [00:02<00:13,  6.53it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 46 features selected for STABL Lasso\n",
      "This fold: 115 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  15%|█▌        | 15/100 [00:02<00:12,  6.58it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 42 features selected for STABL Lasso\n",
      "This fold: 39 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 13 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  16%|█▌        | 16/100 [00:02<00:11,  7.08it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 62 features selected for STABL Lasso\n",
      "This fold: 354 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  17%|█▋        | 17/100 [00:03<00:14,  5.64it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 35 features selected for STABL Lasso\n",
      "This fold: 50 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 23 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  18%|█▊        | 18/100 [00:03<00:13,  6.31it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 30 features selected for STABL Lasso\n",
      "This fold: 143 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  19%|█▉        | 19/100 [00:03<00:12,  6.35it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 34 features selected for STABL Lasso\n",
      "This fold: 25 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 4 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  20%|██        | 20/100 [00:03<00:11,  7.10it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 40 features selected for STABL Lasso\n",
      "This fold: 120 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  21%|██        | 21/100 [00:03<00:12,  6.57it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 27 features selected for STABL Lasso\n",
      "This fold: 700 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  22%|██▏       | 22/100 [00:04<00:18,  4.31it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 68 features selected for STABL Lasso\n",
      "This fold: 130 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 21 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  23%|██▎       | 23/100 [00:04<00:16,  4.61it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 42 features selected for STABL Lasso\n",
      "This fold: 79 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  24%|██▍       | 24/100 [00:04<00:14,  5.21it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 35 features selected for STABL Lasso\n",
      "This fold: 420 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 8 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  25%|██▌       | 25/100 [00:04<00:16,  4.48it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 45 features selected for STABL Lasso\n",
      "This fold: 208 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 11 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  26%|██▌       | 26/100 [00:04<00:16,  4.61it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 32 features selected for STABL Lasso\n",
      "This fold: 126 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  27%|██▋       | 27/100 [00:04<00:14,  5.04it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 12 features selected for STABL Lasso\n",
      "This fold: 7 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 3 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  27%|██▋       | 27/100 [00:05<00:14,  5.04it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 48 features selected for STABL Lasso\n",
      "This fold: 200 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  29%|██▉       | 29/100 [00:05<00:12,  5.82it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 48 features selected for STABL Lasso\n",
      "This fold: 314 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 11 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  30%|███       | 30/100 [00:05<00:13,  5.23it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 30 features selected for STABL Lasso\n",
      "This fold: 89 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 11 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  31%|███       | 31/100 [00:05<00:12,  5.54it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 43 features selected for STABL Lasso\n",
      "This fold: 25 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 1 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  32%|███▏      | 32/100 [00:05<00:11,  6.14it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 23 features selected for STABL Lasso\n",
      "This fold: 473 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 2 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  33%|███▎      | 33/100 [00:06<00:14,  4.78it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 30 features selected for STABL Lasso\n",
      "This fold: 160 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 10 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  34%|███▍      | 34/100 [00:06<00:13,  5.05it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 61 features selected for STABL Lasso\n",
      "This fold: 369 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  35%|███▌      | 35/100 [00:06<00:15,  4.32it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 56 features selected for STABL Lasso\n",
      "This fold: 341 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  36%|███▌      | 36/100 [00:06<00:15,  4.12it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 60 features selected for STABL Lasso\n",
      "This fold: 592 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 14 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  37%|███▋      | 37/100 [00:07<00:18,  3.44it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 51 features selected for STABL Lasso\n",
      "This fold: 374 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 8 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  38%|███▊      | 38/100 [00:07<00:17,  3.47it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 32 features selected for STABL Lasso\n",
      "This fold: 117 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 3 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  39%|███▉      | 39/100 [00:07<00:14,  4.07it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 36 features selected for STABL Lasso\n",
      "This fold: 171 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 8 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  40%|████      | 40/100 [00:07<00:13,  4.39it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 34 features selected for STABL Lasso\n",
      "This fold: 170 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  41%|████      | 41/100 [00:08<00:12,  4.69it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 27 features selected for STABL Lasso\n",
      "This fold: 210 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 8 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  42%|████▏     | 42/100 [00:08<00:12,  4.79it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 47 features selected for STABL Lasso\n",
      "This fold: 145 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  43%|████▎     | 43/100 [00:08<00:11,  5.02it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 67 features selected for STABL Lasso\n",
      "This fold: 190 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  44%|████▍     | 44/100 [00:08<00:11,  4.99it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 43 features selected for STABL Lasso\n",
      "This fold: 180 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  45%|████▌     | 45/100 [00:08<00:10,  5.03it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 56 features selected for STABL Lasso\n",
      "This fold: 75 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 14 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  46%|████▌     | 46/100 [00:08<00:09,  5.47it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 53 features selected for STABL Lasso\n",
      "This fold: 747 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  47%|████▋     | 47/100 [00:09<00:14,  3.67it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 37 features selected for STABL Lasso\n",
      "This fold: 328 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  48%|████▊     | 48/100 [00:09<00:14,  3.68it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 29 features selected for STABL Lasso\n",
      "This fold: 71 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 8 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  49%|████▉     | 49/100 [00:09<00:11,  4.39it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 38 features selected for STABL Lasso\n",
      "This fold: 165 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 12 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  50%|█████     | 50/100 [00:10<00:10,  4.65it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 30 features selected for STABL Lasso\n",
      "This fold: 109 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 14 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  51%|█████     | 51/100 [00:10<00:09,  5.12it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 29 features selected for STABL Lasso\n",
      "This fold: 42 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  52%|█████▏    | 52/100 [00:10<00:08,  5.86it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 15 features selected for STABL Lasso\n",
      "This fold: 15 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  52%|█████▏    | 52/100 [00:10<00:08,  5.86it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 33 features selected for STABL Lasso\n",
      "This fold: 168 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  54%|█████▍    | 54/100 [00:10<00:07,  6.44it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 37 features selected for STABL Lasso\n",
      "This fold: 373 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 4 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  55%|█████▌    | 55/100 [00:10<00:08,  5.24it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 61 features selected for STABL Lasso\n",
      "This fold: 219 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  56%|█████▌    | 56/100 [00:11<00:08,  5.05it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 45 features selected for STABL Lasso\n",
      "This fold: 223 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 12 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  57%|█████▋    | 57/100 [00:11<00:08,  4.92it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 50 features selected for STABL Lasso\n",
      "This fold: 443 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  58%|█████▊    | 58/100 [00:11<00:10,  4.14it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 71 features selected for STABL Lasso\n",
      "This fold: 162 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  59%|█████▉    | 59/100 [00:11<00:09,  4.37it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 69 features selected for STABL Lasso\n",
      "This fold: 513 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 8 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  60%|██████    | 60/100 [00:12<00:10,  3.70it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 36 features selected for STABL Lasso\n",
      "This fold: 276 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 2 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  61%|██████    | 61/100 [00:12<00:10,  3.85it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 40 features selected for STABL Lasso\n",
      "This fold: 211 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  62%|██████▏   | 62/100 [00:12<00:09,  4.08it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 11 features selected for STABL Lasso\n",
      "This fold: 36 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  63%|██████▎   | 63/100 [00:12<00:07,  4.91it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 27 features selected for STABL Lasso\n",
      "This fold: 52 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  64%|██████▍   | 64/100 [00:12<00:06,  5.58it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 27 features selected for STABL Lasso\n",
      "This fold: 168 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 2 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  65%|██████▌   | 65/100 [00:13<00:06,  5.59it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 48 features selected for STABL Lasso\n",
      "This fold: 82 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 11 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  66%|██████▌   | 66/100 [00:13<00:05,  5.82it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 43 features selected for STABL Lasso\n",
      "This fold: 218 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  67%|██████▋   | 67/100 [00:13<00:06,  5.38it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 38 features selected for STABL Lasso\n",
      "This fold: 422 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 11 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  68%|██████▊   | 68/100 [00:13<00:07,  4.45it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 34 features selected for STABL Lasso\n",
      "This fold: 114 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 19 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  69%|██████▉   | 69/100 [00:13<00:06,  4.86it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 30 features selected for STABL Lasso\n",
      "This fold: 164 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  70%|███████   | 70/100 [00:14<00:06,  4.77it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 28 features selected for STABL Lasso\n",
      "This fold: 220 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 4 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  71%|███████   | 71/100 [00:14<00:06,  4.77it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 40 features selected for STABL Lasso\n",
      "This fold: 231 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 13 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  72%|███████▏  | 72/100 [00:14<00:05,  4.73it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 40 features selected for STABL Lasso\n",
      "This fold: 99 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 12 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  73%|███████▎  | 73/100 [00:14<00:05,  5.17it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 44 features selected for STABL Lasso\n",
      "This fold: 291 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 4 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  74%|███████▍  | 74/100 [00:14<00:05,  4.74it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 45 features selected for STABL Lasso\n",
      "This fold: 191 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  75%|███████▌  | 75/100 [00:15<00:05,  4.82it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 45 features selected for STABL Lasso\n",
      "This fold: 110 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 10 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  76%|███████▌  | 76/100 [00:15<00:04,  5.17it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 35 features selected for STABL Lasso\n",
      "This fold: 121 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 12 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  77%|███████▋  | 77/100 [00:15<00:04,  5.17it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 38 features selected for STABL Lasso\n",
      "This fold: 11 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  78%|███████▊  | 78/100 [00:15<00:03,  5.99it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 37 features selected for STABL Lasso\n",
      "This fold: 214 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 10 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  79%|███████▉  | 79/100 [00:15<00:03,  5.44it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 50 features selected for STABL Lasso\n",
      "This fold: 173 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  80%|████████  | 80/100 [00:16<00:03,  5.37it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 42 features selected for STABL Lasso\n",
      "This fold: 153 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 11 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  81%|████████  | 81/100 [00:16<00:03,  5.37it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 61 features selected for STABL Lasso\n",
      "This fold: 51 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  82%|████████▏ | 82/100 [00:16<00:03,  5.86it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 36 features selected for STABL Lasso\n",
      "This fold: 169 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  83%|████████▎ | 83/100 [00:16<00:03,  5.65it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 48 features selected for STABL Lasso\n",
      "This fold: 117 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  84%|████████▍ | 84/100 [00:16<00:02,  5.80it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 49 features selected for STABL Lasso\n",
      "This fold: 66 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 3 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  85%|████████▌ | 85/100 [00:16<00:02,  6.19it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 41 features selected for STABL Lasso\n",
      "This fold: 245 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 10 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  86%|████████▌ | 86/100 [00:17<00:02,  5.51it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 35 features selected for STABL Lasso\n",
      "This fold: 316 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  87%|████████▋ | 87/100 [00:17<00:02,  4.90it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 48 features selected for STABL Lasso\n",
      "This fold: 495 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  88%|████████▊ | 88/100 [00:17<00:03,  3.98it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 55 features selected for STABL Lasso\n",
      "This fold: 77 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  89%|████████▉ | 89/100 [00:17<00:02,  4.58it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 72 features selected for STABL Lasso\n",
      "This fold: 54 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 8 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  90%|█████████ | 90/100 [00:17<00:01,  5.03it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 30 features selected for STABL Lasso\n",
      "This fold: 538 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  91%|█████████ | 91/100 [00:18<00:02,  3.98it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 21 features selected for STABL Lasso\n",
      "This fold: 112 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 17 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  92%|█████████▏| 92/100 [00:18<00:01,  4.47it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 22 features selected for STABL Lasso\n",
      "This fold: 79 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 16 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  93%|█████████▎| 93/100 [00:18<00:01,  4.90it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 21 features selected for STABL Lasso\n",
      "This fold: 557 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  94%|█████████▍| 94/100 [00:19<00:01,  3.67it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 33 features selected for STABL Lasso\n",
      "This fold: 330 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 12 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  95%|█████████▌| 95/100 [00:19<00:01,  3.50it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 59 features selected for STABL Lasso\n",
      "This fold: 179 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 11 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  96%|█████████▌| 96/100 [00:19<00:01,  3.67it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 40 features selected for STABL Lasso\n",
      "This fold: 89 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 8 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  97%|█████████▋| 97/100 [00:19<00:00,  4.06it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 29 features selected for STABL Lasso\n",
      "This fold: 165 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  98%|█████████▊| 98/100 [00:20<00:00,  4.15it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 32 features selected for STABL Lasso\n",
      "This fold: 24 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  99%|█████████▉| 99/100 [00:20<00:00,  4.67it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 42 features selected for STABL Lasso\n",
      "This fold: 791 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples: 100%|██████████| 100/100 [00:20<00:00,  4.81it/s]\n",
      "Saving results...\n",
      "[INFO] Comparing with cv_on_existing_feats using existing selections from: /Users/noeamar/Documents/Stanford/results_cls_24c_CyTOF_xgboost_knockoff_shap_CLS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV: 100%|██████████| 100/100 [01:22<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STABL Lasso sampleID\n",
      "BBCR0002      0.156201\n",
      "BBCR0003      0.070953\n",
      "BBCR0005-1    0.036685\n",
      "BBCR0006      0.037055\n",
      "BBCR0007      0.054711\n",
      "                ...   \n",
      "BBCR0319      0.213661\n",
      "BBCR0327      0.019168\n",
      "BBCR0328      0.034958\n",
      "BBCR0329      0.260888\n",
      "BBCR0338      0.275634\n",
      "Length: 91, dtype: float32\n",
      "STABL ElasticNet sampleID\n",
      "BBCR0002      0.184156\n",
      "BBCR0003      0.108035\n",
      "BBCR0005-1    0.036078\n",
      "BBCR0006      0.052397\n",
      "BBCR0007      0.087836\n",
      "                ...   \n",
      "BBCR0319      0.115432\n",
      "BBCR0327      0.027934\n",
      "BBCR0328      0.052606\n",
      "BBCR0329      0.187648\n",
      "BBCR0338      0.112948\n",
      "Length: 91, dtype: float32\n",
      "STABL ALasso sampleID\n",
      "BBCR0002      0.5\n",
      "BBCR0003      0.5\n",
      "BBCR0005-1    0.5\n",
      "BBCR0006      0.5\n",
      "BBCR0007      0.5\n",
      "             ... \n",
      "BBCR0319      0.5\n",
      "BBCR0327      0.5\n",
      "BBCR0328      0.5\n",
      "BBCR0329      0.5\n",
      "BBCR0338      0.5\n",
      "Length: 91, dtype: float64\n",
      "STABL XGBoost sampleID\n",
      "BBCR0002      0.082850\n",
      "BBCR0003      0.049179\n",
      "BBCR0005-1    0.043061\n",
      "BBCR0006      0.092490\n",
      "BBCR0007      0.041539\n",
      "                ...   \n",
      "BBCR0319      0.322288\n",
      "BBCR0327      0.052688\n",
      "BBCR0328      0.106373\n",
      "BBCR0329      0.066054\n",
      "BBCR0338      0.384967\n",
      "Length: 91, dtype: float32\n",
      "STABL Lasso sampleID\n",
      "BBCR0002      0.159393\n",
      "BBCR0003      0.024214\n",
      "BBCR0005-1    0.021432\n",
      "BBCR0006      0.013626\n",
      "BBCR0007      0.014239\n",
      "                ...   \n",
      "BBCR0319      0.136595\n",
      "BBCR0327      0.004328\n",
      "BBCR0328      0.011922\n",
      "BBCR0329      0.261613\n",
      "BBCR0338      0.192589\n",
      "Length: 91, dtype: float32\n",
      "STABL ElasticNet sampleID\n",
      "BBCR0002      0.358429\n",
      "BBCR0003      0.066515\n",
      "BBCR0005-1    0.016137\n",
      "BBCR0006      0.014339\n",
      "BBCR0007      0.067539\n",
      "                ...   \n",
      "BBCR0319      0.042953\n",
      "BBCR0327      0.011701\n",
      "BBCR0328      0.014678\n",
      "BBCR0329      0.122435\n",
      "BBCR0338      0.059192\n",
      "Length: 91, dtype: float32\n",
      "STABL ALasso sampleID\n",
      "BBCR0002      0.5\n",
      "BBCR0003      0.5\n",
      "BBCR0005-1    0.5\n",
      "BBCR0006      0.5\n",
      "BBCR0007      0.5\n",
      "             ... \n",
      "BBCR0319      0.5\n",
      "BBCR0327      0.5\n",
      "BBCR0328      0.5\n",
      "BBCR0329      0.5\n",
      "BBCR0338      0.5\n",
      "Length: 91, dtype: float64\n",
      "STABL XGBoost sampleID\n",
      "BBCR0002      0.014358\n",
      "BBCR0003      0.007377\n",
      "BBCR0005-1    0.013481\n",
      "BBCR0006      0.014290\n",
      "BBCR0007      0.004041\n",
      "                ...   \n",
      "BBCR0319      0.302116\n",
      "BBCR0327      0.005545\n",
      "BBCR0328      0.027596\n",
      "BBCR0329      0.012173\n",
      "BBCR0338      0.640239\n",
      "Length: 91, dtype: float32\n",
      "STABL Lasso (existing-fit) sampleID\n",
      "BBCR0002      0.156201\n",
      "BBCR0003      0.070953\n",
      "BBCR0005-1    0.036685\n",
      "BBCR0006      0.037055\n",
      "BBCR0007      0.054711\n",
      "                ...   \n",
      "BBCR0319      0.213661\n",
      "BBCR0327      0.019168\n",
      "BBCR0328      0.034958\n",
      "BBCR0329      0.260888\n",
      "BBCR0338      0.275634\n",
      "Length: 91, dtype: float32\n",
      "STABL ElasticNet (existing-fit) sampleID\n",
      "BBCR0002      0.184156\n",
      "BBCR0003      0.108035\n",
      "BBCR0005-1    0.036078\n",
      "BBCR0006      0.052397\n",
      "BBCR0007      0.087836\n",
      "                ...   \n",
      "BBCR0319      0.115432\n",
      "BBCR0327      0.027934\n",
      "BBCR0328      0.052606\n",
      "BBCR0329      0.187648\n",
      "BBCR0338      0.112948\n",
      "Length: 91, dtype: float32\n",
      "STABL ALasso (existing-fit) sampleID\n",
      "BBCR0002      0.5\n",
      "BBCR0003      0.5\n",
      "BBCR0005-1    0.5\n",
      "BBCR0006      0.5\n",
      "BBCR0007      0.5\n",
      "             ... \n",
      "BBCR0319      0.5\n",
      "BBCR0327      0.5\n",
      "BBCR0328      0.5\n",
      "BBCR0329      0.5\n",
      "BBCR0338      0.5\n",
      "Length: 91, dtype: float64\n",
      "STABL XGBoost (existing-fit) sampleID\n",
      "BBCR0002      0.082850\n",
      "BBCR0003      0.049179\n",
      "BBCR0005-1    0.043061\n",
      "BBCR0006      0.092490\n",
      "BBCR0007      0.041539\n",
      "                ...   \n",
      "BBCR0319      0.322288\n",
      "BBCR0327      0.052688\n",
      "BBCR0328      0.106373\n",
      "BBCR0329      0.066054\n",
      "BBCR0338      0.384967\n",
      "Length: 91, dtype: float32\n",
      "✓ Terminé.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# --- CONFIG ---\n",
    "# Renseigne ces 3 chemins + options. Laisse le reste par défaut.\n",
    "\n",
    "DATA_ROOT       = \"/Users/noeamar/Documents/Stanford/data/Biobank SSI\"  # dossier du dataset\n",
    "FOLD_FEATS_PATH = \"/Users/noeamar/Documents/Stanford/results_cls_24c_CyTOF_xgboost_knockoff_shap_CLS\"  # run existant avec Selected Features *.csv\n",
    "SAVE_ROOT       = \"results_CI_SSI_vf_xgb_shap_existing_notebook\"  # dossier de sortie pour CE run\n",
    "\n",
    "DATASET         = \"ssi\"               # \"ssi\" (par défaut) ou \"onset\"\n",
    "MODEL_CHOSEN    = \"xgboost\"          # pour la comparaison 'existing-fit' : \"xgboost\" | \"random_forest\" | \"logit\"\n",
    "N_SPLITS        = 100\n",
    "TEST_SIZE       = 0.2\n",
    "RANDOM_STATE    = 42\n",
    "\n",
    "# Optionnel : ajouter des combos Union/Intersect entre STABL models si présents dans FOLD_FEATS_PATH\n",
    "ADD_COMBOS      = False  # True pour générer Union/Intersect 2-à-2\n",
    "\n",
    "\n",
    "# %%\n",
    "import os\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# Dataset loaders & STABL pipeline\n",
    "from stabl.data import load_ssi, load_onset_of_labor\n",
    "from stabl.multi_omic_pipelines import multi_omic_stabl_cv_noe_test  # <- ta fonction modifiée\n",
    "\n",
    "# %%\n",
    "DATA_ROOT = Path(DATA_ROOT)\n",
    "FOLD_FEATS_PATH = Path(FOLD_FEATS_PATH)\n",
    "SAVE_ROOT = Path(SAVE_ROOT)\n",
    "SAVE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if DATASET == \"ssi\":\n",
    "    train_dict, _, y, _, _, task_type = load_ssi(str(DATA_ROOT))\n",
    "    y = y.astype(int)\n",
    "    assert set(y.unique()) <= {0, 1}, f\"Labels non binaires: {sorted(y.unique())}\"\n",
    "    cyto = train_dict[\"CyTOF\"]\n",
    "    prot = train_dict[\"Proteomics\"].copy()\n",
    "    prot.columns = [f\"PRO_{c}\" for c in prot.columns]  # évite collisions de noms\n",
    "    common = y.index\n",
    "    for df in (cyto, prot):\n",
    "        common = common.intersection(df.index)\n",
    "    y = y.loc[common]\n",
    "    X = pd.concat([cyto.loc[common], prot.loc[common]], axis=1)\n",
    "else:\n",
    "    train_dict, valid_data_dict, y, y_valid, patients_id, task_type = load_onset_of_labor(str(DATA_ROOT))\n",
    "    cyto = train_dict[\"CyTOF\"]\n",
    "    prot = train_dict[\"Proteomics\"].copy()\n",
    "    prot.columns = [f\"PRO_{c}\" for c in prot.columns]\n",
    "    common = y.index\n",
    "    for df in (cyto, prot):\n",
    "        common = common.intersection(df.index)\n",
    "    y = y.loc[common]\n",
    "    X = pd.concat([cyto.loc[common], prot.loc[common]], axis=1)\n",
    "\n",
    "print(f\"X shape: {X.shape} | y: {y.shape} | task_type: {task_type}\")\n",
    "display(X.head(2))\n",
    "display(y.value_counts())\n",
    "\n",
    "\n",
    "# %%\n",
    "# Groupes par patient (avant l'underscore)\n",
    "groups = X.index.to_series().str.split(\"_\").str[0]\n",
    "splitter = GroupShuffleSplit(n_splits=N_SPLITS, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "# Early-fusion dans un seul \"omic\"\n",
    "data_dict = {\"allstim\": X}\n",
    "\n",
    "# On propose comme base ces modèles; on filtre ceux dont les CSV existent réellement\n",
    "candidate_stabl = [\"STABL Lasso\", \"STABL ElasticNet\", \"STABL ALasso\", \"STABL XGBoost\"]\n",
    "available = []\n",
    "for m in candidate_stabl:\n",
    "    csv_path = FOLD_FEATS_PATH / \"Training CV\" / f\"Selected Features {m}.csv\"\n",
    "    if csv_path.exists():\n",
    "        available.append(m)\n",
    "    else:\n",
    "        print(f\"[WARN] Missing features file for {m}: {csv_path}\")\n",
    "\n",
    "if not available:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Aucun CSV 'Selected Features {{model}}.csv' trouvé dans {FOLD_FEATS_PATH/'Training CV'}.\\n\"\n",
    "        \"Vérifie les noms exacts de modèles et le chemin 'fold_feats_path'.\"\n",
    "    )\n",
    "\n",
    "# Optionnel : Union/Intersect 2-à-2 des modèles disponibles\n",
    "models = list(available)\n",
    "if ADD_COMBOS and len(available) >= 2:\n",
    "    sep = \" & \"\n",
    "    combos = []\n",
    "    for group in itertools.combinations(available, 2):\n",
    "        combos += [f\"Union {sep.join(group)}\", f\"Intersect {sep.join(group)}\"]\n",
    "    models += combos\n",
    "\n",
    "print(\"Models utilisés :\", models)\n",
    "\n",
    "# %%\n",
    "# Estimateurs pour le refit (utilisés par la comparaison \"existing-fit\" et par le fit de notre run)\n",
    "rf_cls = RandomForestClassifier(\n",
    "    n_estimators=600, max_depth=8, min_samples_split=2, min_samples_leaf=2,\n",
    "    max_features=\"sqrt\", ccp_alpha=1e-3, random_state=RANDOM_STATE, n_jobs=-1\n",
    ")\n",
    "xgb_cls = XGBClassifier(\n",
    "    n_estimators=800, learning_rate=0.01, max_depth=3,\n",
    "    subsample=0.6, colsample_bytree=0.5, random_state=RANDOM_STATE, n_jobs=-1,\n",
    "    eval_metric=\"logloss\", use_label_encoder=False\n",
    ")\n",
    "\n",
    "# Dictionnaire des estimateurs — seules ces clés sont requises en \"skip selection\"\n",
    "estimators = {\n",
    "    \"rf\": rf_cls,\n",
    "    \"xgb\": xgb_cls,\n",
    "    # noms attendus par cv_on_existing_feats (la fonction mappe rf/xgb → ces clés si besoin)\n",
    "    \"random_forest\": rf_cls,\n",
    "    \"xgboost\": xgb_cls,\n",
    "    \n",
    "    # placeholders (non utilisés car on skippe la sélection)\n",
    "    \"lasso\": None, \"en\": None, \"alasso\": None,\n",
    "    \"stabl_lasso\": None, \"stabl_alasso\": None, \"stabl_en\": None, \"stabl_xgb\": None,\n",
    "}\n",
    "\n",
    "print(\"Estimators ready.\")\n",
    "\n",
    "# %%\n",
    "print(\"[INFO] Starting CV with skip-selection (using existing STABL features)...\")\n",
    "preds = multi_omic_stabl_cv_noe_test(\n",
    "    data_dict       = data_dict,\n",
    "    y               = y,\n",
    "    outer_splitter  = splitter,\n",
    "    estimators      = estimators,\n",
    "    task_type       = task_type,            # \"binary\" pour SSI\n",
    "    model_chosen    = MODEL_CHOSEN,         # \"xgboost\" recommandé\n",
    "    models          = models,\n",
    "    save_path       = str(SAVE_ROOT),\n",
    "    outer_groups    = groups,\n",
    "    early_fusion    = False,\n",
    "    late_fusion     = False,\n",
    "    n_iter_lf       = 100000,\n",
    "    fold_feats_path = str(FOLD_FEATS_PATH), # là où sont les Selected Features {model}.csv\n",
    "    use_existing_feats_only = True,         # <<< SKIP la sélection; fit uniquement\n",
    ")\n",
    "print(\"✓ Terminé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e0606d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>N features</th>\n",
       "      <th>CVS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STABL Lasso</th>\n",
       "      <td>0.863 [0.769, 0.937]</td>\n",
       "      <td>0.555 [0.331, 0.788]</td>\n",
       "      <td>38.000 [30.000, 48.000]</td>\n",
       "      <td>0.250 [0.203, 0.302]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABL ElasticNet</th>\n",
       "      <td>0.732 [0.603, 0.844]</td>\n",
       "      <td>0.401 [0.220, 0.639]</td>\n",
       "      <td>165.000 [87.250, 252.750]</td>\n",
       "      <td>0.137 [0.070, 0.251]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABL ALasso</th>\n",
       "      <td>0.500 [0.500, 0.500]</td>\n",
       "      <td>0.176 [0.110, 0.253]</td>\n",
       "      <td>0.000 [0.000, 0.000]</td>\n",
       "      <td>0.000 [0.000, 0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABL XGBoost</th>\n",
       "      <td>0.932 [0.852, 0.988]</td>\n",
       "      <td>0.847 [0.684, 0.957]</td>\n",
       "      <td>8.000 [6.000, 11.000]</td>\n",
       "      <td>0.125 [0.067, 0.200]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABL Lasso (existing-fit)</th>\n",
       "      <td>0.884 [0.804, 0.953]</td>\n",
       "      <td>0.597 [0.363, 0.821]</td>\n",
       "      <td>38.000 [30.000, 48.000]</td>\n",
       "      <td>0.033 [0.027, 0.039]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABL ElasticNet (existing-fit)</th>\n",
       "      <td>0.769 [0.662, 0.865]</td>\n",
       "      <td>0.335 [0.200, 0.556]</td>\n",
       "      <td>165.000 [87.250, 252.750]</td>\n",
       "      <td>0.006 [0.005, 0.009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABL ALasso (existing-fit)</th>\n",
       "      <td>0.500 [0.500, 0.500]</td>\n",
       "      <td>0.176 [0.099, 0.253]</td>\n",
       "      <td>0.000 [0.000, 0.000]</td>\n",
       "      <td>1.000 [1.000, 1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABL XGBoost (existing-fit)</th>\n",
       "      <td>0.954 [0.893, 0.995]</td>\n",
       "      <td>0.881 [0.720, 0.979]</td>\n",
       "      <td>8.000 [6.000, 11.000]</td>\n",
       "      <td>0.108 [0.090, 0.130]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ROC AUC     Average Precision  \\\n",
       "STABL Lasso                      0.863 [0.769, 0.937]  0.555 [0.331, 0.788]   \n",
       "STABL ElasticNet                 0.732 [0.603, 0.844]  0.401 [0.220, 0.639]   \n",
       "STABL ALasso                     0.500 [0.500, 0.500]  0.176 [0.110, 0.253]   \n",
       "STABL XGBoost                    0.932 [0.852, 0.988]  0.847 [0.684, 0.957]   \n",
       "STABL Lasso (existing-fit)       0.884 [0.804, 0.953]  0.597 [0.363, 0.821]   \n",
       "STABL ElasticNet (existing-fit)  0.769 [0.662, 0.865]  0.335 [0.200, 0.556]   \n",
       "STABL ALasso (existing-fit)      0.500 [0.500, 0.500]  0.176 [0.099, 0.253]   \n",
       "STABL XGBoost (existing-fit)     0.954 [0.893, 0.995]  0.881 [0.720, 0.979]   \n",
       "\n",
       "                                                N features  \\\n",
       "STABL Lasso                        38.000 [30.000, 48.000]   \n",
       "STABL ElasticNet                 165.000 [87.250, 252.750]   \n",
       "STABL ALasso                          0.000 [0.000, 0.000]   \n",
       "STABL XGBoost                        8.000 [6.000, 11.000]   \n",
       "STABL Lasso (existing-fit)         38.000 [30.000, 48.000]   \n",
       "STABL ElasticNet (existing-fit)  165.000 [87.250, 252.750]   \n",
       "STABL ALasso (existing-fit)           0.000 [0.000, 0.000]   \n",
       "STABL XGBoost (existing-fit)         8.000 [6.000, 11.000]   \n",
       "\n",
       "                                                  CVS  \n",
       "STABL Lasso                      0.250 [0.203, 0.302]  \n",
       "STABL ElasticNet                 0.137 [0.070, 0.251]  \n",
       "STABL ALasso                     0.000 [0.000, 0.000]  \n",
       "STABL XGBoost                    0.125 [0.067, 0.200]  \n",
       "STABL Lasso (existing-fit)       0.033 [0.027, 0.039]  \n",
       "STABL ElasticNet (existing-fit)  0.006 [0.005, 0.009]  \n",
       "STABL ALasso (existing-fit)      1.000 [1.000, 1.000]  \n",
       "STABL XGBoost (existing-fit)     0.108 [0.090, 0.130]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "scores_csv = SAVE_ROOT / \"Summary\" / \"Scores training CV.csv\"\n",
    "if scores_csv.exists():\n",
    "    scores_df = pd.read_csv(scores_csv, index_col=0)\n",
    "    display(scores_df)\n",
    "else:\n",
    "    print(f\"[WARN] Fichier scores introuvable: {scores_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91980ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    folds  mean  median   std  \\\n",
      "file                                                                            \n",
      "Selected Features Intersect STABL ALasso & STAB...    100  3.86     4.0  1.84   \n",
      "Selected Features Intersect STABL Lasso & STABL...    100  4.28     4.0  1.88   \n",
      "Selected Features Intersect STABL Lasso & STABL...    100  4.10     4.0  2.01   \n",
      "Selected Features STABL ALasso.csv                    100  4.61     5.0  1.90   \n",
      "Selected Features STABL ElasticNet.csv                100  7.76     5.0  7.04   \n",
      "Selected Features STABL Lasso.csv                     100  5.53     5.5  2.53   \n",
      "Selected Features Union STABL ALasso & STABL El...    100  8.51     6.0  6.84   \n",
      "Selected Features Union STABL Lasso & STABL ALa...    100  5.86     6.0  2.52   \n",
      "Selected Features Union STABL Lasso & STABL Ela...    100  9.19     7.5  6.82   \n",
      "\n",
      "                                                    min  max   25%    75%  \\\n",
      "file                                                                        \n",
      "Selected Features Intersect STABL ALasso & STAB...    0   10  3.00   5.00   \n",
      "Selected Features Intersect STABL Lasso & STABL...    0   10  3.00   5.25   \n",
      "Selected Features Intersect STABL Lasso & STABL...    0   10  3.00   5.00   \n",
      "Selected Features STABL ALasso.csv                    1   10  3.00   6.00   \n",
      "Selected Features STABL ElasticNet.csv                0   41  4.00   9.00   \n",
      "Selected Features STABL Lasso.csv                     1   14  4.00   7.00   \n",
      "Selected Features Union STABL ALasso & STABL El...    1   42  5.00   9.25   \n",
      "Selected Features Union STABL Lasso & STABL ALa...    1   14  4.00   7.25   \n",
      "Selected Features Union STABL Lasso & STABL Ela...    1   42  5.75  10.25   \n",
      "\n",
      "                                                    unique_feats  \n",
      "file                                                              \n",
      "Selected Features Intersect STABL ALasso & STAB...            38  \n",
      "Selected Features Intersect STABL Lasso & STABL...            39  \n",
      "Selected Features Intersect STABL Lasso & STABL...            41  \n",
      "Selected Features STABL ALasso.csv                            40  \n",
      "Selected Features STABL ElasticNet.csv                       104  \n",
      "Selected Features STABL Lasso.csv                             44  \n",
      "Selected Features Union STABL ALasso & STABL El...           104  \n",
      "Selected Features Union STABL Lasso & STABL ALa...            45  \n",
      "Selected Features Union STABL Lasso & STABL Ela...           105  \n"
     ]
    }
   ],
   "source": [
    "import glob, ast, statistics, os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 1) dossier contenant \"Training CV/Selected Features *.csv\"\n",
    "ROOT = Path(\"/Users/noeamar/Documents/Stanford/Fitting results/SSI/SSI normalized RP_0.01_100 + Logit no intersect\")   # ← à adapter\n",
    "CSV_PATTERN = ROOT / \"Training CV\" / \"Selected Features *.csv\"\n",
    "\n",
    "def to_list(cell):\n",
    "    \"Transforme une cellule en liste de features (ou None).\"\n",
    "    if isinstance(cell, str):\n",
    "        try:\n",
    "            return list(ast.literal_eval(cell))\n",
    "        except Exception:\n",
    "            return None\n",
    "    elif isinstance(cell, (list, tuple, set)):\n",
    "        return list(cell)\n",
    "    return None\n",
    "\n",
    "def count_feats(cell):\n",
    "    \"Renvoie le nombre de features dans la cellule.\"\n",
    "    if isinstance(cell, (int, float)):\n",
    "        return int(cell)\n",
    "    lst = to_list(cell)\n",
    "    return len(lst) if lst is not None else None\n",
    "\n",
    "summary = []\n",
    "\n",
    "for csv in glob.glob(str(CSV_PATTERN)):\n",
    "    df = pd.read_csv(csv, index_col=0)\n",
    "\n",
    "    # 1) Compte par fold\n",
    "    if \"Fold nb of features\" in df.columns:\n",
    "        counts = df[\"Fold nb of features\"].astype(int)\n",
    "    elif \"Fold #features\" in df.columns:\n",
    "        counts = df[\"Fold #features\"].astype(int)\n",
    "    else:  # on recompte à partir de la colonne listes\n",
    "        counts = df.iloc[:, 0].apply(count_feats)\n",
    "\n",
    "    counts = counts.dropna().astype(int)\n",
    "\n",
    "    # 2) Union des features sur tous les folds\n",
    "    if \"Fold selected features\" in df.columns:\n",
    "        all_feats = set().union(*df[\"Fold selected features\"].apply(to_list).dropna())\n",
    "    else:\n",
    "        # si la colonne n'existe pas, on ne peut pas calculer\n",
    "        all_feats = set()\n",
    "\n",
    "    stats = {\n",
    "        \"file\":           os.path.basename(csv),\n",
    "        \"folds\":          len(counts),\n",
    "        \"mean\":           counts.mean(),\n",
    "        \"median\":         counts.median(),\n",
    "        \"std\":            counts.std(ddof=1),\n",
    "        \"min\":            counts.min(),\n",
    "        \"max\":            counts.max(),\n",
    "        \"25%\":            counts.quantile(0.25),\n",
    "        \"75%\":            counts.quantile(0.75),\n",
    "        \"unique_feats\":   len(all_feats) if all_feats else \"n/a\",\n",
    "    }\n",
    "    summary.append(stats)\n",
    "\n",
    "summary_df = (\n",
    "    pd.DataFrame(summary)\n",
    "      .set_index(\"file\")\n",
    "      .round(2)\n",
    "      .sort_index()\n",
    ")\n",
    "print(summary_df)\n",
    "\n",
    "# (option) sauvegarder\n",
    "summary_df.to_csv(ROOT / \"summary_feature_counts.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Common_venv (3.9.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1a28266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels uniques: [0, 1]\n",
      "Taille de CyTOF : (93, 1125)\n",
      "Taille de Proteomics : (91, 721)\n",
      "Taille de X : (93, 1846)\n",
      "Taille de y : (93,)\n",
      "Union STABL XGBoost & STABL ALasso: Moyenne=33.0, Médiane=32.0\n",
      "Intersect STABL XGBoost & STABL ALasso: Moyenne=4.9, Médiane=5.0\n",
      "2 → Union STABL XGBoost & STABL ALasso / Intersect STABL XGBoost & STABL ALasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV:   0%|          | 0/25 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 391\u001b[0m\n\u001b[1;32m    380\u001b[0m estimators \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogit\u001b[39m\u001b[38;5;124m\"\u001b[39m : Logit,\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_forest\u001b[39m\u001b[38;5;124m\"\u001b[39m: rf_cls,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \n\u001b[1;32m    388\u001b[0m }\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# 3.6 Lancement\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mcv_on_existing_feats\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mouter_splitter\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimators\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mestimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_chosen\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxgboost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Choix du modèle de base pour les non-STABL\u001b[39;49;00m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_feats_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFOLD_FEATS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSAVE_ROOT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mouter_groups\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m→ Terminé, prédictions agrégées renvoyées.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[91], line 139\u001b[0m, in \u001b[0;36mcv_on_existing_feats\u001b[0;34m(data_dict, y, outer_splitter, estimators, task_type, model_chosen, models, fold_feats_path, save_path, outer_groups, early_fusion, late_fusion, n_iter_lf, use_ega)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    138\u001b[0m     est \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgboost\u001b[39m\u001b[38;5;124m\"\u001b[39m: xgb_est, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_forest\u001b[39m\u001b[38;5;124m\"\u001b[39m: rf_est, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit}\u001b[38;5;241m.\u001b[39mget(model_chosen, logit)\n\u001b[0;32m--> 139\u001b[0m     pr  \u001b[38;5;241m=\u001b[39m \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_ids\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpredict_proba(Xte)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     est \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgboost\u001b[39m\u001b[38;5;124m\"\u001b[39m: xgb_est, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_forest\u001b[39m\u001b[38;5;124m\"\u001b[39m: rf_est}\u001b[38;5;241m.\u001b[39mget(model_chosen, linreg)\n",
      "File \u001b[0;32m~/Documents/Stanford/Common_venv/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Stanford/Common_venv/lib/python3.9/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/Stanford/Common_venv/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Stanford/Common_venv/lib/python3.9/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Stanford/Common_venv/lib/python3.9/site-packages/xgboost/core.py:1915\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtrain, DMatrix):\n\u001b[1;32m   1914\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid training matrix: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(dtrain)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1915\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_dmatrix_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     _check_call(_LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[38;5;241m.\u001b[39mhandle))\n",
      "File \u001b[0;32m~/Documents/Stanford/Common_venv/lib/python3.9/site-packages/xgboost/core.py:2744\u001b[0m, in \u001b[0;36mBooster._validate_dmatrix_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2743\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names \u001b[38;5;241m=\u001b[39m fn\n\u001b[0;32m-> 2744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_types\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2745\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types \u001b[38;5;241m=\u001b[39m ft\n\u001b[1;32m   2747\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(fn)\n",
      "File \u001b[0;32m~/Documents/Stanford/Common_venv/lib/python3.9/site-packages/xgboost/core.py:1856\u001b[0m, in \u001b[0;36mBooster.feature_types\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfeature_types\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[FeatureTypes]:\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Feature types for this booster.  Can be directly set by input data or by\u001b[39;00m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;124;03m    assignment.  See :py:class:`DMatrix` for details.\u001b[39;00m\n\u001b[1;32m   1854\u001b[0m \n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_feature_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeature_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Stanford/Common_venv/lib/python3.9/site-packages/xgboost/core.py:1830\u001b[0m, in \u001b[0;36mBooster._get_feature_info\u001b[0;34m(self, field)\u001b[0m\n\u001b[1;32m   1824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1825\u001b[0m _check_call(\n\u001b[1;32m   1826\u001b[0m     _LIB\u001b[38;5;241m.\u001b[39mXGBoosterGetStrFeatureInfo(\n\u001b[1;32m   1827\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, c_str(field), ctypes\u001b[38;5;241m.\u001b[39mbyref(length), ctypes\u001b[38;5;241m.\u001b[39mbyref(sarr),\n\u001b[1;32m   1828\u001b[0m     )\n\u001b[1;32m   1829\u001b[0m )\n\u001b[0;32m-> 1830\u001b[0m feature_info \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_cstr_to_pystr\u001b[49m\u001b[43m(\u001b[49m\u001b[43msarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1831\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature_info \u001b[38;5;28;01mif\u001b[39;00m feature_info \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Stanford/Common_venv/lib/python3.9/site-packages/xgboost/core.py:102\u001b[0m, in \u001b[0;36mfrom_cstr_to_pystr\u001b[0;34m(data, length)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(length\u001b[38;5;241m.\u001b[39mvalue):\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m         res\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mascii\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m         res\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(cast(\u001b[38;5;28mbytes\u001b[39m, data[i])\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit, RepeatedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, ElasticNet\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from stabl.data import load_onset_of_labor, load_ssi\n",
    "from stabl.multi_omic_pipelines import multi_omic_stabl_cv_noe_test\n",
    "\n",
    "# STABL imports\n",
    "from stabl.adaptive import ALasso\n",
    "from stabl.stabl import Stabl\n",
    "from stabl.preprocessing import remove_low_info_samples, LowInfoFilter\n",
    "from stabl.pipelines_utils import compute_scores_table, save_plots\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. Définition des estimateurs STABL\n",
    "# -------------------------------------------------------------------\n",
    "inner_cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=42)\n",
    "lasso  = Lasso(max_iter=int(1e6), random_state=42)\n",
    "en     = ElasticNet(max_iter=int(1e6), random_state=42)\n",
    "alasso = ALasso(max_iter=int(1e6), random_state=42)\n",
    "xgb    = XGBRegressor(random_state=42, importance_type=\"gain\", objective=\"reg:squarederror\")\n",
    "\n",
    "stabl_lasso = Stabl(\n",
    "    base_estimator=lasso, n_bootstraps=1000,\n",
    "    artificial_type=\"knockoff\", artificial_proportion=1.0,\n",
    "    replace=False, fdr_threshold_range=np.arange(0.1,1,0.01),\n",
    "    sample_fraction=0.5, random_state=42,\n",
    "    lambda_grid={\"alpha\": np.logspace(0,2,10)}, verbose=1,\n",
    ")\n",
    "stabl_alasso = clone(stabl_lasso).set_params(base_estimator=alasso)\n",
    "stabl_en     = clone(stabl_lasso).set_params(\n",
    "    base_estimator=en,\n",
    "    lambda_grid={\"alpha\": np.logspace(0.5,2,10), \"l1_ratio\":[0.5,0.7,0.9]}\n",
    ")\n",
    "stabl_xgb    = Stabl(\n",
    "    base_estimator=xgb, n_bootstraps=1000,\n",
    "    artificial_type=\"knockoff\", artificial_proportion=1.0,\n",
    "    replace=False, fdr_threshold_range=np.arange(0.1,1,0.01),\n",
    "    sample_fraction=0.5, random_state=42,\n",
    "    lambda_grid={\"max_depth\":[3,6,9], \"reg_alpha\":[0,0.5,1,2]},\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. Fonction de CV sur features existantes (avec union/intersect)\n",
    "# -------------------------------------------------------------------\n",
    "def cv_on_existing_feats(\n",
    "    data_dict, y, outer_splitter,\n",
    "    estimators, task_type, model_chosen,\n",
    "    models, fold_feats_path, save_path,\n",
    "    outer_groups=None, early_fusion=False,\n",
    "    late_fusion=False, n_iter_lf=10000,\n",
    "    use_ega=False\n",
    "):\n",
    "    logit   = LogisticRegression(max_iter=1000)\n",
    "    linreg  = LinearRegression()\n",
    "    rf_est  = estimators[\"random_forest\"]\n",
    "    xgb_est = estimators[\"xgboost\"]\n",
    "\n",
    "    os.makedirs(Path(save_path, \"Training CV\"), exist_ok=True)\n",
    "    os.makedirs(Path(save_path, \"Summary\"),     exist_ok=True)\n",
    "\n",
    "    X_tot = pd.concat(data_dict.values(), axis=1)\n",
    "    preds_dict   = {m: pd.DataFrame(index=y.index) for m in models}\n",
    "    feats_dict   = {m: [] for m in models}\n",
    "\n",
    "    # Lecture des sélections STABL originales\n",
    "    raw_sel = {}\n",
    "    for m in models:\n",
    "        if m.startswith(\"STABL \"):\n",
    "            df = pd.read_csv(Path(fold_feats_path,\"Training CV\",f\"Selected Features {m}.csv\"), index_col=0)\n",
    "            raw_sel[m] = [\n",
    "                eval(s) if isinstance(s,str) else s\n",
    "                for s in df[\"Fold selected features\"]\n",
    "            ]\n",
    "\n",
    "    n_splits = outer_splitter.get_n_splits(X=X_tot, y=y, groups=outer_groups)\n",
    "\n",
    "    for fold_idx, (train_i, test_i) in enumerate(tqdm(\n",
    "        outer_splitter.split(X_tot, y, groups=outer_groups),\n",
    "        total=n_splits, desc=\"Outer CV\"\n",
    "    )):\n",
    "        train_ids = y.iloc[train_i].index\n",
    "        test_ids  = y.iloc[test_i].index\n",
    "\n",
    "        # On récupère pour chaque modèle la liste de features\n",
    "        for m in models:\n",
    "            if m.startswith(\"Union \"):\n",
    "                # \"Union STABL Lasso & STABL ALasso\" → ['STABL Lasso','STABL ALasso']\n",
    "                bases = m.replace(\"Union \",\"\").split(\" & \")\n",
    "                sets  = [ set(raw_sel[b][fold_idx]) for b in bases ]\n",
    "                feats = list(set.union(*sets))\n",
    "            # elif m.startswith(\"Intersect \"):\n",
    "            #     bases = m.replace(\"Intersect \",\"\").split(\" & \")\n",
    "            #     sets  = [ set(raw_sel[b][fold_idx]) for b in bases ]\n",
    "            #     feats = list(set.intersection(*sets))\n",
    "            elif m.startswith(\"STABL \"):\n",
    "                feats = raw_sel[m][fold_idx]\n",
    "            else:\n",
    "                # non-STABL → on peut choisir all‑features ou fallback\n",
    "                feats = list(X_tot.columns)\n",
    "\n",
    "            # Fit / predict\n",
    "            if len(feats)==0:\n",
    "                val = (0.5 if task_type==\"binary\" else np.mean(y.loc[train_ids]))\n",
    "                preds_dict[m].loc[test_ids, f\"Fold_{fold_idx}\"] = val\n",
    "            else:\n",
    "                pipe = Pipeline([\n",
    "                    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                    (\"scaler\",  StandardScaler())\n",
    "                ])\n",
    "                Xtr = pd.DataFrame(pipe.fit_transform(X_tot.loc[train_ids, feats]),\n",
    "                                   index=train_ids, columns=feats)\n",
    "                Xte = pd.DataFrame(pipe.transform(X_tot.loc[test_ids, feats]),\n",
    "                                   index=test_ids,  columns=feats)\n",
    "\n",
    "                key = (model_chosen or \"logit\").lower()\n",
    "\n",
    "                if task_type == \"binary\":\n",
    "                    est = {\"xgboost\": xgb_est, \"random_forest\": rf_est, \"logit\": logit}.get(model_chosen, logit)\n",
    "                    pr  = clone(est).fit(Xtr, y.loc[train_ids]).predict_proba(Xte)[:, 1]\n",
    "                else:\n",
    "                    est = {\"xgboost\": xgb_est, \"random_forest\": rf_est}.get(model_chosen, linreg)\n",
    "                    pr  = clone(est).fit(Xtr, y.loc[train_ids]).predict(Xte)\n",
    "\n",
    "                preds_dict[m].loc[test_ids, f\"Fold_{fold_idx}\"] = pr\n",
    "\n",
    "            feats_dict[m].append(feats)\n",
    "\n",
    "    # Sauvegarde des listes\n",
    "    cv_dir = Path(save_path,\"Training CV\")\n",
    "    for m in models:\n",
    "        dfm = pd.DataFrame({\n",
    "            \"Fold selected features\": feats_dict[m],\n",
    "            \"Fold #features\": [len(f) for f in feats_dict[m]]\n",
    "        }, index=[f\"Fold_{i}\" for i in range(n_splits)])\n",
    "        dfm.to_csv(cv_dir/f\"Selected Features {m}.csv\")\n",
    "\n",
    "    # Scores & plots\n",
    "    summary_dir = Path(save_path,\"Summary\")\n",
    "    med_preds = {m: preds_dict[m].median(axis=1) for m in models}\n",
    "    scores = compute_scores_table(\n",
    "        predictions_dict=med_preds,\n",
    "        y=y,\n",
    "        task_type=task_type,\n",
    "        selected_features_dict=None\n",
    "    )\n",
    "    scores.to_csv(summary_dir / \"Scores_training_CV.csv\")\n",
    "    save_plots(\n",
    "        predictions_dict=med_preds,\n",
    "        y=y,\n",
    "        task_type=task_type,\n",
    "        save_path=cv_dir\n",
    "     )\n",
    "\n",
    "    return med_preds\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Point d'entrée\n",
    "# -------------------------------------------------------------------\n",
    "if __name__==\"__main__\":\n",
    "    # 3.1 \n",
    "    X_PATH     = Path(\"/Users/noeamar/Documents/Stanford/data/olivier_data/ina_13OG_final_long_allstims_filtered (6).csv\")\n",
    "    Y_PATH     = Path(\"/Users/noeamar/Documents/Stanford/data/olivier_data/outcome_table_all_pre.csv\")\n",
    "    FOLD_FEATS = Path(\"/Users/noeamar/Documents/Stanford/Benchmarks results/SSI + XGB/KO\")\n",
    "    SAVE_ROOT  = Path(\"out\")\n",
    "\n",
    "    # # Load INA\n",
    "    # X = pd.read_csv(X_PATH, index_col=0)\n",
    "    # y = pd.read_csv(Y_PATH, index_col=0).squeeze()\n",
    "    # common = X.index.intersection(y.index)\n",
    "    # X, y = X.loc[common], y.loc[common]\n",
    "\n",
    "    # # # 3.2 Splitter & data_dict\n",
    "    # task_type = \"regression\"\n",
    "    # groups   = X.index.to_series().str.split(\"_\").str[0]\n",
    "    # splitter = GroupShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "    # data_dict= {\"allstim\": X}\n",
    "\n",
    "    # # 1) Load OOL\n",
    "    # train_dict, valid_data_dict, y, y_valid, patients_id, task_type = load_onset_of_labor(\n",
    "    # \"/Users/noeamar/Documents/Stanford/data/Onset of Labor\"\n",
    "    # )\n",
    "\n",
    "    # cyto_train = train_dict[\"CyTOF\"]\n",
    "    # prot_train = train_dict[\"Proteomics\"].copy()\n",
    "    # # Préfixe PRO_ pour distinguer les colonnes\n",
    "    # prot_train.columns = [f\"{c}\" for c in prot_train.columns]\n",
    "\n",
    "    # # 2) Intersection des index sur (y, cyto, prot)\n",
    "    # common = y.index\n",
    "    # for df in (cyto_train, prot_train):\n",
    "    #     common = common.intersection(df.index)\n",
    "\n",
    "    # y = y.loc[common]\n",
    "    # cyto_train = cyto_train.loc[common]\n",
    "    # prot_train = prot_train.loc[common]\n",
    "\n",
    "    # # 3) Early-fusion: un seul X\n",
    "    # X = pd.concat([cyto_train, prot_train], axis=1)\n",
    "\n",
    "    # # 4) Splitter & data_dict (un seul bloc \"allstim\")\n",
    "    # groups   = X.index.to_series().str.split(\"_\").str[0]\n",
    "    # splitter = GroupShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "    # data_dict = {\"allstim\": X}\n",
    "\n",
    "    # Load SSI\n",
    "    train_data_dict, _, y, _, _, task_type = load_ssi(\"/Users/noeamar/Documents/Stanford/data/Biobank SSI\")  # task_type = \"binary\"\n",
    "    \n",
    "    # Assainir les labels\n",
    "    y = y.astype(int)\n",
    "    vals = sorted(set(y.unique()))\n",
    "    print(\"Labels uniques:\", vals)  # doit afficher [0, 1]\n",
    "    assert set(vals) <= {0, 1}\n",
    "\n",
    "    # 3) Early-fusion: concat CyTOF + Proteomics en un seul X\n",
    "    cyto = train_data_dict[\"CyTOF\"]\n",
    "    prot = train_data_dict[\"Proteomics\"].copy()\n",
    "    print(\"Taille de CyTOF :\", cyto.shape)\n",
    "    print(\"Taille de Proteomics :\", prot.shape)\n",
    "    # (Option recommandé) Préfixer la protéomique pour éviter toute collision de noms :\n",
    "    #prot.columns = [f\"PRO_{c}\" for c in prot.columns]\n",
    "\n",
    "    # 4) Aligner les index sur l’intersection commune (y, cyto, prot)\n",
    "    # common = y.index\n",
    "    # for df in (cyto, prot):\n",
    "    #     common = common.intersection(df.index)\n",
    "\n",
    "    # y = y.loc[common]\n",
    "    # X = pd.concat([cyto.loc[common], prot.loc[common]], axis=1)\n",
    "\n",
    "    X=pd.concat([cyto, prot], axis=1)\n",
    "    print(\"Taille de X :\", X.shape)\n",
    "    print(\"Taille de y :\", y.shape)\n",
    "\n",
    "    # print(\"\\n--- VERSION INTERSECTION COMMUNE ---\")\n",
    "\n",
    "    # # Index de départ\n",
    "    # print(\"Index y :\", y.index.tolist())\n",
    "    # print(\"Index cyto :\", cyto.index.tolist())\n",
    "    # print(\"Index prot :\", prot.index.tolist())\n",
    "\n",
    "    # # Intersection progressive\n",
    "    # common = y.index\n",
    "    # print(\"\\nÉtape 0 - common (y.index) :\", common.tolist())\n",
    "\n",
    "    # for i, df in enumerate((cyto, prot), start=1):\n",
    "    #     common = common.intersection(df.index)\n",
    "    #     print(f\"Étape {i} - intersection avec df{i} :\", common.tolist())\n",
    "\n",
    "    # # Sélection finale\n",
    "    # y_common = y.loc[common]\n",
    "    # X_common = pd.concat([cyto.loc[common], prot.loc[common]], axis=1)\n",
    "\n",
    "    # print(\"\\nTaille finale y_common :\", y_common.shape)\n",
    "    # print(\"Taille finale X_common :\", X_common.shape)\n",
    "    # print(\"Index final commun :\", common.tolist())\n",
    "\n",
    "    # # Exemple de premières lignes\n",
    "    # print(\"\\nAperçu X_common :\")\n",
    "    # print(X_common.head())\n",
    "\n",
    "    # # ------------------------\n",
    "    # print(\"\\n--- VERSION CONCAT SIMPLE ---\")\n",
    "    # X_simple = pd.concat([cyto, prot], axis=1)\n",
    "\n",
    "    # print(\"Taille X_simple :\", X_simple.shape)\n",
    "    # print(\"Index X_simple :\", X_simple.index.tolist())\n",
    "\n",
    "    # # Vérification des NaN éventuels\n",
    "    # nan_counts = X_simple.isna().sum().sum()\n",
    "    # print(\"Nombre total de NaN dans X_simple :\", nan_counts)\n",
    "\n",
    "    #(Option) S’assurer que y est bien 0/1\n",
    "    y = y.astype(int)\n",
    "\n",
    "    # 5) Splitter & data_dict (identique à ton snippet)\n",
    "    groups   = X.index.to_series().str.split(\"_\").str[0]\n",
    "    #splitter = GroupShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "    splitter=RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "    data_dict = {\"allstim\": X}\n",
    "\n",
    "    # # Load COVID-19\n",
    "    # from stabl.data import load_covid_19\n",
    "    # X_train, X_valid, y_train, y_valid, ids, task_type = load_covid_19(\"data/COVID-19\")\n",
    "    # # Assainir les labels\n",
    "    # y_train = y_train.astype(int)\n",
    "    # y_valid = y_valid.astype(int)\n",
    "    # vals = sorted(set(y_valid.unique()))\n",
    "    # print(\"Labels uniques:\", vals)  # doit afficher [0, 1]\n",
    "    # assert set(vals) <= {0, 1} \n",
    "    # data_dict = X_valid\n",
    "    # # If X_valid is a dict, print the shape of each DataFrame inside\n",
    "    # if isinstance(X_valid, dict):\n",
    "    #     for k, v in X_valid.items():\n",
    "    #         print(f\"X_valid[{k}] shape:\", v.shape)\n",
    "    # else:\n",
    "    #     print(\"X_valid shape:\", X_valid.shape)\n",
    "\n",
    "    # if isinstance(X_train, dict):\n",
    "    #     for k, v in X_valid.items():\n",
    "    #         print(f\"X_train[{k}] shape:\", v.shape)\n",
    "    # else:\n",
    "    #     print(\"X_train shape:\", X_valid.shape)\n",
    "    # splitter = RepeatedStratifiedKFold(n_splits=5, n_repeats=20, random_state=42)\n",
    "    # y= y_valid\n",
    "    # groups = ids\n",
    "\n",
    "    # 3.3 Liste initiale de modèles STABL\n",
    "    #stabl_models = [\"STABL Lasso\", \"STABL XGBoost\", \"STABL ALasso\", \"STABL ElasticNet\"]\n",
    "    stabl_models = [\"STABL XGBoost\", \"STABL ALasso\"]\n",
    "    base_models  = stabl_models\n",
    "\n",
    "    xgb_param_grid = {\n",
    "    \"n_estimators\": [170],\n",
    "    \"learning_rate\": [0.005],\n",
    "    \"max_depth\": [6],\n",
    "    \"subsample\": [1],\n",
    "    \"colsample_bytree\": [1]\n",
    "    }\n",
    "\n",
    "    rf_reg = RandomForestRegressor(n_estimators=600, max_depth=8, min_samples_split=2, min_samples_leaf=2, max_features=\"sqrt\", ccp_alpha=1e-3, random_state=42, n_jobs=-1)\n",
    "    xgb_reg = XGBRegressor(n_estimators=800, learning_rate=0.01, max_depth=3, subsample=0.6, colsample_bytree=0.5 ,random_state=42, n_jobs=-1)\n",
    "    linreg  = LinearRegression(fit_intercept=True, copy_X=False, positive=True, n_jobs=-1)\n",
    "    rf_cls = RandomForestClassifier(n_estimators=600, max_depth=8, min_samples_split=2, min_samples_leaf=2, max_features=\"sqrt\", ccp_alpha=1e-3, random_state=42, n_jobs=-1)\n",
    "    xgb_cls = XGBClassifier(n_estimators=800, learning_rate=0.01, max_depth=3, subsample=0.6, colsample_bytree=0.5 ,random_state=42, n_jobs=-1)\n",
    "    Logit = LogisticRegression(penalty=None, class_weight=\"balanced\", max_iter=int(1e6), random_state=42)\n",
    "    xgb_test = XGBClassifier()\n",
    "    #xgb_grid = GridSearchCV(estimator=xgb_cls, param_grid=xgb_param_grid, cv=inner_cv, scoring=\"roc_auc\", n_jobs=-1, verbose=2, refit=True)\n",
    "    # 3.4 Génération autom. des combos 2‑à‑2 et 3‑à‑3\n",
    "    combos = []\n",
    "    for r in [2]:\n",
    "        for group in itertools.combinations(stabl_models, r):\n",
    "            sep = \" & \"\n",
    "            combos += [f\"Union {sep.join(group)}\", f\"Intersect {sep.join(group)}\"]\n",
    "            # Calcul du nombre de features pour chaque combo\n",
    "            # Calcul du nombre de features pour chaque combo, par fold\n",
    "            for combo in combos:\n",
    "                bases = combo.replace(\"Union \", \"\").replace(\"Intersect \", \"\").split(sep)\n",
    "                # Lecture des features sélectionnés pour chaque modèle de base, par fold\n",
    "                fold_feats = []\n",
    "                for b in bases:\n",
    "                    df = pd.read_csv(Path(FOLD_FEATS, \"Training CV\", f\"Selected Features {b}.csv\"), index_col=0)\n",
    "                    # Chaque ligne = liste de features pour le fold\n",
    "                    fold_feats.append(df[\"Fold selected features\"].apply(eval))\n",
    "                # Calcul union/intersection par fold\n",
    "                fold_counts = []\n",
    "                for fold_idx in range(len(fold_feats[0])):\n",
    "                    sets_fold = [set(f[fold_idx]) if isinstance(f[fold_idx], (list, set)) else set() for f in fold_feats]\n",
    "                    if combo.startswith(\"Union \"):\n",
    "                        feats_fold = set.union(*sets_fold)\n",
    "                    else:\n",
    "                        feats_fold = set.intersection(*sets_fold)\n",
    "                    fold_counts.append(len(feats_fold))\n",
    "                print(f\"{combo}: Moyenne={np.mean(fold_counts):.1f}, Médiane={np.median(fold_counts):.1f}\")\n",
    "            print(len(combos), f\"→ {combos[-2]} / {combos[-1]}\")\n",
    "\n",
    "    models = base_models + combos\n",
    "\n",
    "    # 3.5 Estimateurs à passer\n",
    "    estimators = {\n",
    "        \"Logit\" : Logit,\n",
    "        \"random_forest\": rf_cls,\n",
    "        \"xgboost\":       xgb_cls,\n",
    "        \"stabl_alasso\":  stabl_alasso,\n",
    "        \"stabl_en\":      stabl_en,\n",
    "        \"linreg\":      linreg,\n",
    "        \n",
    "    }\n",
    "\n",
    "    # 3.6 Lancement\n",
    "    preds = cv_on_existing_feats(\n",
    "        data_dict       = data_dict,\n",
    "        y               = y,\n",
    "        outer_splitter  = splitter,\n",
    "        estimators      = estimators,\n",
    "        task_type       = task_type,\n",
    "        model_chosen    = \"xgboost\",  # Choix du modèle de base pour les non-STABL\n",
    "        models          = models,\n",
    "        fold_feats_path = FOLD_FEATS,\n",
    "        save_path       = SAVE_ROOT,\n",
    "        outer_groups    = groups,\n",
    "    )\n",
    "\n",
    "    print(\"→ Terminé, prédictions agrégées renvoyées.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be799462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noeamar/Documents/Stanford/stablVMax/stabl/multi_omic_pipelines.py:3: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (91, 1846) | y: (91,) | task_type: binary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unstim_Baso_149Sm_CREB</th>\n",
       "      <th>unstim_Baso_150Nd_STAT5</th>\n",
       "      <th>unstim_Baso_151Eu_p38</th>\n",
       "      <th>unstim_Baso_153Eu_STAT1</th>\n",
       "      <th>unstim_Baso_154Sm_STAT3</th>\n",
       "      <th>unstim_Baso_155Gd_S6</th>\n",
       "      <th>unstim_Baso_159Tb_MAPKAPK2</th>\n",
       "      <th>unstim_Baso_164Dy_IkB</th>\n",
       "      <th>unstim_Baso_166Er_NFkB</th>\n",
       "      <th>unstim_Baso_167Er_ERK</th>\n",
       "      <th>...</th>\n",
       "      <th>PRO_SAT1</th>\n",
       "      <th>PRO_NFKB1</th>\n",
       "      <th>PRO_CDKN2B</th>\n",
       "      <th>PRO_RAP2A</th>\n",
       "      <th>PRO_XRCC4</th>\n",
       "      <th>PRO_ARID1A</th>\n",
       "      <th>PRO_EGLN1</th>\n",
       "      <th>PRO_TOPBP1</th>\n",
       "      <th>PRO_SLC22A16</th>\n",
       "      <th>PRO_IRF6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampleID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BBCR0002</th>\n",
       "      <td>0.632924</td>\n",
       "      <td>0.344065</td>\n",
       "      <td>0.028052</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.143817</td>\n",
       "      <td>0.150393</td>\n",
       "      <td>0.801140</td>\n",
       "      <td>0.681250</td>\n",
       "      <td>0.031901</td>\n",
       "      <td>...</td>\n",
       "      <td>9.571184</td>\n",
       "      <td>11.314243</td>\n",
       "      <td>10.127736</td>\n",
       "      <td>9.873905</td>\n",
       "      <td>8.623150</td>\n",
       "      <td>9.615262</td>\n",
       "      <td>10.399064</td>\n",
       "      <td>8.828454</td>\n",
       "      <td>12.143543</td>\n",
       "      <td>11.980247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBCR0003</th>\n",
       "      <td>0.921823</td>\n",
       "      <td>0.677804</td>\n",
       "      <td>0.041205</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>1.614141</td>\n",
       "      <td>0.138246</td>\n",
       "      <td>0.966064</td>\n",
       "      <td>0.562168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.349171</td>\n",
       "      <td>13.429106</td>\n",
       "      <td>9.698531</td>\n",
       "      <td>9.763378</td>\n",
       "      <td>8.799929</td>\n",
       "      <td>9.465362</td>\n",
       "      <td>10.176298</td>\n",
       "      <td>8.386294</td>\n",
       "      <td>12.561980</td>\n",
       "      <td>11.355186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1846 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          unstim_Baso_149Sm_CREB  unstim_Baso_150Nd_STAT5  \\\n",
       "sampleID                                                    \n",
       "BBCR0002                0.632924                 0.344065   \n",
       "BBCR0003                0.921823                 0.677804   \n",
       "\n",
       "          unstim_Baso_151Eu_p38  unstim_Baso_153Eu_STAT1  \\\n",
       "sampleID                                                   \n",
       "BBCR0002               0.028052                        0   \n",
       "BBCR0003               0.041205                        0   \n",
       "\n",
       "          unstim_Baso_154Sm_STAT3  unstim_Baso_155Gd_S6  \\\n",
       "sampleID                                                  \n",
       "BBCR0002                 0.000000              1.143817   \n",
       "BBCR0003                 0.000672              1.614141   \n",
       "\n",
       "          unstim_Baso_159Tb_MAPKAPK2  unstim_Baso_164Dy_IkB  \\\n",
       "sampleID                                                      \n",
       "BBCR0002                    0.150393               0.801140   \n",
       "BBCR0003                    0.138246               0.966064   \n",
       "\n",
       "          unstim_Baso_166Er_NFkB  unstim_Baso_167Er_ERK  ...  PRO_SAT1  \\\n",
       "sampleID                                                 ...             \n",
       "BBCR0002                0.681250               0.031901  ...  9.571184   \n",
       "BBCR0003                0.562168               0.000000  ...  9.349171   \n",
       "\n",
       "          PRO_NFKB1  PRO_CDKN2B  PRO_RAP2A  PRO_XRCC4  PRO_ARID1A  PRO_EGLN1  \\\n",
       "sampleID                                                                       \n",
       "BBCR0002  11.314243   10.127736   9.873905   8.623150    9.615262  10.399064   \n",
       "BBCR0003  13.429106    9.698531   9.763378   8.799929    9.465362  10.176298   \n",
       "\n",
       "          PRO_TOPBP1  PRO_SLC22A16   PRO_IRF6  \n",
       "sampleID                                       \n",
       "BBCR0002    8.828454     12.143543  11.980247  \n",
       "BBCR0003    8.386294     12.561980  11.355186  \n",
       "\n",
       "[2 rows x 1846 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model1b\n",
       "0    75\n",
       "1    16\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models utilisés : ['STABL Lasso', 'STABL ElasticNet', 'STABL ALasso', 'STABL XGBoost']\n",
      "Estimators ready.\n",
      "[INFO] Starting CV with skip-selection (using existing STABL features)...\n",
      "72 train samples, 19 test samples:   0%|          | 0/100 [00:00<?, ?it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 28 features selected for STABL Lasso\n",
      "This fold: 108 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 10 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   1%|          | 1/100 [00:00<00:18,  5.38it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 37 features selected for STABL Lasso\n",
      "This fold: 51 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 14 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   2%|▏         | 2/100 [00:00<00:16,  6.12it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 23 features selected for STABL Lasso\n",
      "This fold: 109 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   3%|▎         | 3/100 [00:00<00:18,  5.22it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 57 features selected for STABL Lasso\n",
      "This fold: 191 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   4%|▍         | 4/100 [00:00<00:18,  5.23it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 27 features selected for STABL Lasso\n",
      "This fold: 370 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 13 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   5%|▌         | 5/100 [00:01<00:20,  4.67it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 30 features selected for STABL Lasso\n",
      "This fold: 66 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 14 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   6%|▌         | 6/100 [00:01<00:17,  5.30it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 72 features selected for STABL Lasso\n",
      "This fold: 165 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 2 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   7%|▋         | 7/100 [00:01<00:17,  5.24it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 26 features selected for STABL Lasso\n",
      "This fold: 28 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 12 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   8%|▊         | 8/100 [00:01<00:15,  5.81it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 25 features selected for STABL Lasso\n",
      "This fold: 321 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:   9%|▉         | 9/100 [00:01<00:17,  5.07it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 30 features selected for STABL Lasso\n",
      "This fold: 237 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 12 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  10%|█         | 10/100 [00:01<00:18,  4.95it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 44 features selected for STABL Lasso\n",
      "This fold: 117 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 12 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  11%|█         | 11/100 [00:02<00:17,  5.16it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 38 features selected for STABL Lasso\n",
      "This fold: 41 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 15 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  12%|█▏        | 12/100 [00:02<00:15,  5.80it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 49 features selected for STABL Lasso\n",
      "This fold: 156 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 16 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  13%|█▎        | 13/100 [00:02<00:15,  5.70it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 31 features selected for STABL Lasso\n",
      "This fold: 15 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 11 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  14%|█▍        | 14/100 [00:02<00:13,  6.53it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 46 features selected for STABL Lasso\n",
      "This fold: 115 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  15%|█▌        | 15/100 [00:02<00:12,  6.58it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 42 features selected for STABL Lasso\n",
      "This fold: 39 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 13 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  16%|█▌        | 16/100 [00:02<00:11,  7.08it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 62 features selected for STABL Lasso\n",
      "This fold: 354 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  17%|█▋        | 17/100 [00:03<00:14,  5.64it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 35 features selected for STABL Lasso\n",
      "This fold: 50 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 23 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  18%|█▊        | 18/100 [00:03<00:13,  6.31it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 30 features selected for STABL Lasso\n",
      "This fold: 143 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  19%|█▉        | 19/100 [00:03<00:12,  6.35it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 34 features selected for STABL Lasso\n",
      "This fold: 25 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 4 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  20%|██        | 20/100 [00:03<00:11,  7.10it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 40 features selected for STABL Lasso\n",
      "This fold: 120 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  21%|██        | 21/100 [00:03<00:12,  6.57it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 27 features selected for STABL Lasso\n",
      "This fold: 700 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  22%|██▏       | 22/100 [00:04<00:18,  4.31it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 68 features selected for STABL Lasso\n",
      "This fold: 130 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 21 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  23%|██▎       | 23/100 [00:04<00:16,  4.61it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 42 features selected for STABL Lasso\n",
      "This fold: 79 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  24%|██▍       | 24/100 [00:04<00:14,  5.21it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 35 features selected for STABL Lasso\n",
      "This fold: 420 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 8 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  25%|██▌       | 25/100 [00:04<00:16,  4.48it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 45 features selected for STABL Lasso\n",
      "This fold: 208 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 11 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  26%|██▌       | 26/100 [00:04<00:16,  4.61it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 32 features selected for STABL Lasso\n",
      "This fold: 126 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  27%|██▋       | 27/100 [00:04<00:14,  5.04it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 12 features selected for STABL Lasso\n",
      "This fold: 7 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 3 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  27%|██▋       | 27/100 [00:05<00:14,  5.04it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 48 features selected for STABL Lasso\n",
      "This fold: 200 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  29%|██▉       | 29/100 [00:05<00:12,  5.82it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 48 features selected for STABL Lasso\n",
      "This fold: 314 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 11 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  30%|███       | 30/100 [00:05<00:13,  5.23it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 30 features selected for STABL Lasso\n",
      "This fold: 89 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 11 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  31%|███       | 31/100 [00:05<00:12,  5.54it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 43 features selected for STABL Lasso\n",
      "This fold: 25 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 1 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  32%|███▏      | 32/100 [00:05<00:11,  6.14it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 23 features selected for STABL Lasso\n",
      "This fold: 473 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 2 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  33%|███▎      | 33/100 [00:06<00:14,  4.78it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 30 features selected for STABL Lasso\n",
      "This fold: 160 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 10 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  34%|███▍      | 34/100 [00:06<00:13,  5.05it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 61 features selected for STABL Lasso\n",
      "This fold: 369 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  35%|███▌      | 35/100 [00:06<00:15,  4.32it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 56 features selected for STABL Lasso\n",
      "This fold: 341 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  36%|███▌      | 36/100 [00:06<00:15,  4.12it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 60 features selected for STABL Lasso\n",
      "This fold: 592 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 14 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  37%|███▋      | 37/100 [00:07<00:18,  3.44it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 51 features selected for STABL Lasso\n",
      "This fold: 374 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 8 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  38%|███▊      | 38/100 [00:07<00:17,  3.47it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 32 features selected for STABL Lasso\n",
      "This fold: 117 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 3 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  39%|███▉      | 39/100 [00:07<00:14,  4.07it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 36 features selected for STABL Lasso\n",
      "This fold: 171 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 8 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  40%|████      | 40/100 [00:07<00:13,  4.39it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 34 features selected for STABL Lasso\n",
      "This fold: 170 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  41%|████      | 41/100 [00:08<00:12,  4.69it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 27 features selected for STABL Lasso\n",
      "This fold: 210 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 8 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  42%|████▏     | 42/100 [00:08<00:12,  4.79it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 47 features selected for STABL Lasso\n",
      "This fold: 145 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  43%|████▎     | 43/100 [00:08<00:11,  5.02it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 67 features selected for STABL Lasso\n",
      "This fold: 190 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  44%|████▍     | 44/100 [00:08<00:11,  4.99it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 43 features selected for STABL Lasso\n",
      "This fold: 180 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  45%|████▌     | 45/100 [00:08<00:10,  5.03it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 56 features selected for STABL Lasso\n",
      "This fold: 75 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 14 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  46%|████▌     | 46/100 [00:08<00:09,  5.47it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 53 features selected for STABL Lasso\n",
      "This fold: 747 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  47%|████▋     | 47/100 [00:09<00:14,  3.67it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 37 features selected for STABL Lasso\n",
      "This fold: 328 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  48%|████▊     | 48/100 [00:09<00:14,  3.68it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 29 features selected for STABL Lasso\n",
      "This fold: 71 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 8 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  49%|████▉     | 49/100 [00:09<00:11,  4.39it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 38 features selected for STABL Lasso\n",
      "This fold: 165 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 12 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  50%|█████     | 50/100 [00:10<00:10,  4.65it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 30 features selected for STABL Lasso\n",
      "This fold: 109 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 14 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  51%|█████     | 51/100 [00:10<00:09,  5.12it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 29 features selected for STABL Lasso\n",
      "This fold: 42 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  52%|█████▏    | 52/100 [00:10<00:08,  5.86it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 15 features selected for STABL Lasso\n",
      "This fold: 15 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  52%|█████▏    | 52/100 [00:10<00:08,  5.86it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 33 features selected for STABL Lasso\n",
      "This fold: 168 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  54%|█████▍    | 54/100 [00:10<00:07,  6.44it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 37 features selected for STABL Lasso\n",
      "This fold: 373 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 4 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  55%|█████▌    | 55/100 [00:10<00:08,  5.24it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 61 features selected for STABL Lasso\n",
      "This fold: 219 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  56%|█████▌    | 56/100 [00:11<00:08,  5.05it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 45 features selected for STABL Lasso\n",
      "This fold: 223 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 12 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  57%|█████▋    | 57/100 [00:11<00:08,  4.92it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 50 features selected for STABL Lasso\n",
      "This fold: 443 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  58%|█████▊    | 58/100 [00:11<00:10,  4.14it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 71 features selected for STABL Lasso\n",
      "This fold: 162 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  59%|█████▉    | 59/100 [00:11<00:09,  4.37it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 69 features selected for STABL Lasso\n",
      "This fold: 513 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 8 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  60%|██████    | 60/100 [00:12<00:10,  3.70it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 36 features selected for STABL Lasso\n",
      "This fold: 276 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 2 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  61%|██████    | 61/100 [00:12<00:10,  3.85it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 40 features selected for STABL Lasso\n",
      "This fold: 211 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  62%|██████▏   | 62/100 [00:12<00:09,  4.08it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 11 features selected for STABL Lasso\n",
      "This fold: 36 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  63%|██████▎   | 63/100 [00:12<00:07,  4.91it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 27 features selected for STABL Lasso\n",
      "This fold: 52 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  64%|██████▍   | 64/100 [00:12<00:06,  5.58it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 27 features selected for STABL Lasso\n",
      "This fold: 168 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 2 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  65%|██████▌   | 65/100 [00:13<00:06,  5.59it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 48 features selected for STABL Lasso\n",
      "This fold: 82 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 11 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  66%|██████▌   | 66/100 [00:13<00:05,  5.82it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 43 features selected for STABL Lasso\n",
      "This fold: 218 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  67%|██████▋   | 67/100 [00:13<00:06,  5.38it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 38 features selected for STABL Lasso\n",
      "This fold: 422 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 11 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  68%|██████▊   | 68/100 [00:13<00:07,  4.45it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 34 features selected for STABL Lasso\n",
      "This fold: 114 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 19 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  69%|██████▉   | 69/100 [00:13<00:06,  4.86it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 30 features selected for STABL Lasso\n",
      "This fold: 164 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  70%|███████   | 70/100 [00:14<00:06,  4.77it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 28 features selected for STABL Lasso\n",
      "This fold: 220 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 4 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  71%|███████   | 71/100 [00:14<00:06,  4.77it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 40 features selected for STABL Lasso\n",
      "This fold: 231 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 13 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  72%|███████▏  | 72/100 [00:14<00:05,  4.73it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 40 features selected for STABL Lasso\n",
      "This fold: 99 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 12 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  73%|███████▎  | 73/100 [00:14<00:05,  5.17it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 44 features selected for STABL Lasso\n",
      "This fold: 291 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 4 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  74%|███████▍  | 74/100 [00:14<00:05,  4.74it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 45 features selected for STABL Lasso\n",
      "This fold: 191 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  75%|███████▌  | 75/100 [00:15<00:05,  4.82it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 45 features selected for STABL Lasso\n",
      "This fold: 110 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 10 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  76%|███████▌  | 76/100 [00:15<00:04,  5.17it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 35 features selected for STABL Lasso\n",
      "This fold: 121 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 12 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  77%|███████▋  | 77/100 [00:15<00:04,  5.17it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 38 features selected for STABL Lasso\n",
      "This fold: 11 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  78%|███████▊  | 78/100 [00:15<00:03,  5.99it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 37 features selected for STABL Lasso\n",
      "This fold: 214 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 10 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  79%|███████▉  | 79/100 [00:15<00:03,  5.44it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 50 features selected for STABL Lasso\n",
      "This fold: 173 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  80%|████████  | 80/100 [00:16<00:03,  5.37it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 42 features selected for STABL Lasso\n",
      "This fold: 153 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 11 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  81%|████████  | 81/100 [00:16<00:03,  5.37it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 61 features selected for STABL Lasso\n",
      "This fold: 51 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  82%|████████▏ | 82/100 [00:16<00:03,  5.86it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 36 features selected for STABL Lasso\n",
      "This fold: 169 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  83%|████████▎ | 83/100 [00:16<00:03,  5.65it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 48 features selected for STABL Lasso\n",
      "This fold: 117 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 7 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  84%|████████▍ | 84/100 [00:16<00:02,  5.80it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 49 features selected for STABL Lasso\n",
      "This fold: 66 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 3 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  85%|████████▌ | 85/100 [00:16<00:02,  6.19it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 41 features selected for STABL Lasso\n",
      "This fold: 245 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 10 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  86%|████████▌ | 86/100 [00:17<00:02,  5.51it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 35 features selected for STABL Lasso\n",
      "This fold: 316 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  87%|████████▋ | 87/100 [00:17<00:02,  4.90it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 48 features selected for STABL Lasso\n",
      "This fold: 495 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  88%|████████▊ | 88/100 [00:17<00:03,  3.98it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 55 features selected for STABL Lasso\n",
      "This fold: 77 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  89%|████████▉ | 89/100 [00:17<00:02,  4.58it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 72 features selected for STABL Lasso\n",
      "This fold: 54 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 8 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  90%|█████████ | 90/100 [00:17<00:01,  5.03it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 30 features selected for STABL Lasso\n",
      "This fold: 538 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 5 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  91%|█████████ | 91/100 [00:18<00:02,  3.98it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 21 features selected for STABL Lasso\n",
      "This fold: 112 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 17 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  92%|█████████▏| 92/100 [00:18<00:01,  4.47it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 22 features selected for STABL Lasso\n",
      "This fold: 79 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 16 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  93%|█████████▎| 93/100 [00:18<00:01,  4.90it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 21 features selected for STABL Lasso\n",
      "This fold: 557 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  94%|█████████▍| 94/100 [00:19<00:01,  3.67it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 33 features selected for STABL Lasso\n",
      "This fold: 330 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 12 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  95%|█████████▌| 95/100 [00:19<00:01,  3.50it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 59 features selected for STABL Lasso\n",
      "This fold: 179 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 11 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  96%|█████████▌| 96/100 [00:19<00:01,  3.67it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 40 features selected for STABL Lasso\n",
      "This fold: 89 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 8 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  97%|█████████▋| 97/100 [00:19<00:00,  4.06it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 29 features selected for STABL Lasso\n",
      "This fold: 165 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  98%|█████████▊| 98/100 [00:20<00:00,  4.15it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 32 features selected for STABL Lasso\n",
      "This fold: 24 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 9 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples:  99%|█████████▉| 99/100 [00:20<00:00,  4.67it/s]~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 42 features selected for STABL Lasso\n",
      "This fold: 791 features selected for STABL ElasticNet\n",
      "This fold: 0 features selected for STABL ALasso\n",
      "This fold: 6 features selected for STABL XGBoost\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "72 train samples, 19 test samples: 100%|██████████| 100/100 [00:20<00:00,  4.81it/s]\n",
      "Saving results...\n",
      "[INFO] Comparing with cv_on_existing_feats using existing selections from: /Users/noeamar/Documents/Stanford/results_cls_24c_CyTOF_xgboost_knockoff_shap_CLS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV: 100%|██████████| 100/100 [01:22<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STABL Lasso sampleID\n",
      "BBCR0002      0.156201\n",
      "BBCR0003      0.070953\n",
      "BBCR0005-1    0.036685\n",
      "BBCR0006      0.037055\n",
      "BBCR0007      0.054711\n",
      "                ...   \n",
      "BBCR0319      0.213661\n",
      "BBCR0327      0.019168\n",
      "BBCR0328      0.034958\n",
      "BBCR0329      0.260888\n",
      "BBCR0338      0.275634\n",
      "Length: 91, dtype: float32\n",
      "STABL ElasticNet sampleID\n",
      "BBCR0002      0.184156\n",
      "BBCR0003      0.108035\n",
      "BBCR0005-1    0.036078\n",
      "BBCR0006      0.052397\n",
      "BBCR0007      0.087836\n",
      "                ...   \n",
      "BBCR0319      0.115432\n",
      "BBCR0327      0.027934\n",
      "BBCR0328      0.052606\n",
      "BBCR0329      0.187648\n",
      "BBCR0338      0.112948\n",
      "Length: 91, dtype: float32\n",
      "STABL ALasso sampleID\n",
      "BBCR0002      0.5\n",
      "BBCR0003      0.5\n",
      "BBCR0005-1    0.5\n",
      "BBCR0006      0.5\n",
      "BBCR0007      0.5\n",
      "             ... \n",
      "BBCR0319      0.5\n",
      "BBCR0327      0.5\n",
      "BBCR0328      0.5\n",
      "BBCR0329      0.5\n",
      "BBCR0338      0.5\n",
      "Length: 91, dtype: float64\n",
      "STABL XGBoost sampleID\n",
      "BBCR0002      0.082850\n",
      "BBCR0003      0.049179\n",
      "BBCR0005-1    0.043061\n",
      "BBCR0006      0.092490\n",
      "BBCR0007      0.041539\n",
      "                ...   \n",
      "BBCR0319      0.322288\n",
      "BBCR0327      0.052688\n",
      "BBCR0328      0.106373\n",
      "BBCR0329      0.066054\n",
      "BBCR0338      0.384967\n",
      "Length: 91, dtype: float32\n",
      "STABL Lasso sampleID\n",
      "BBCR0002      0.159393\n",
      "BBCR0003      0.024214\n",
      "BBCR0005-1    0.021432\n",
      "BBCR0006      0.013626\n",
      "BBCR0007      0.014239\n",
      "                ...   \n",
      "BBCR0319      0.136595\n",
      "BBCR0327      0.004328\n",
      "BBCR0328      0.011922\n",
      "BBCR0329      0.261613\n",
      "BBCR0338      0.192589\n",
      "Length: 91, dtype: float32\n",
      "STABL ElasticNet sampleID\n",
      "BBCR0002      0.358429\n",
      "BBCR0003      0.066515\n",
      "BBCR0005-1    0.016137\n",
      "BBCR0006      0.014339\n",
      "BBCR0007      0.067539\n",
      "                ...   \n",
      "BBCR0319      0.042953\n",
      "BBCR0327      0.011701\n",
      "BBCR0328      0.014678\n",
      "BBCR0329      0.122435\n",
      "BBCR0338      0.059192\n",
      "Length: 91, dtype: float32\n",
      "STABL ALasso sampleID\n",
      "BBCR0002      0.5\n",
      "BBCR0003      0.5\n",
      "BBCR0005-1    0.5\n",
      "BBCR0006      0.5\n",
      "BBCR0007      0.5\n",
      "             ... \n",
      "BBCR0319      0.5\n",
      "BBCR0327      0.5\n",
      "BBCR0328      0.5\n",
      "BBCR0329      0.5\n",
      "BBCR0338      0.5\n",
      "Length: 91, dtype: float64\n",
      "STABL XGBoost sampleID\n",
      "BBCR0002      0.014358\n",
      "BBCR0003      0.007377\n",
      "BBCR0005-1    0.013481\n",
      "BBCR0006      0.014290\n",
      "BBCR0007      0.004041\n",
      "                ...   \n",
      "BBCR0319      0.302116\n",
      "BBCR0327      0.005545\n",
      "BBCR0328      0.027596\n",
      "BBCR0329      0.012173\n",
      "BBCR0338      0.640239\n",
      "Length: 91, dtype: float32\n",
      "STABL Lasso (existing-fit) sampleID\n",
      "BBCR0002      0.156201\n",
      "BBCR0003      0.070953\n",
      "BBCR0005-1    0.036685\n",
      "BBCR0006      0.037055\n",
      "BBCR0007      0.054711\n",
      "                ...   \n",
      "BBCR0319      0.213661\n",
      "BBCR0327      0.019168\n",
      "BBCR0328      0.034958\n",
      "BBCR0329      0.260888\n",
      "BBCR0338      0.275634\n",
      "Length: 91, dtype: float32\n",
      "STABL ElasticNet (existing-fit) sampleID\n",
      "BBCR0002      0.184156\n",
      "BBCR0003      0.108035\n",
      "BBCR0005-1    0.036078\n",
      "BBCR0006      0.052397\n",
      "BBCR0007      0.087836\n",
      "                ...   \n",
      "BBCR0319      0.115432\n",
      "BBCR0327      0.027934\n",
      "BBCR0328      0.052606\n",
      "BBCR0329      0.187648\n",
      "BBCR0338      0.112948\n",
      "Length: 91, dtype: float32\n",
      "STABL ALasso (existing-fit) sampleID\n",
      "BBCR0002      0.5\n",
      "BBCR0003      0.5\n",
      "BBCR0005-1    0.5\n",
      "BBCR0006      0.5\n",
      "BBCR0007      0.5\n",
      "             ... \n",
      "BBCR0319      0.5\n",
      "BBCR0327      0.5\n",
      "BBCR0328      0.5\n",
      "BBCR0329      0.5\n",
      "BBCR0338      0.5\n",
      "Length: 91, dtype: float64\n",
      "STABL XGBoost (existing-fit) sampleID\n",
      "BBCR0002      0.082850\n",
      "BBCR0003      0.049179\n",
      "BBCR0005-1    0.043061\n",
      "BBCR0006      0.092490\n",
      "BBCR0007      0.041539\n",
      "                ...   \n",
      "BBCR0319      0.322288\n",
      "BBCR0327      0.052688\n",
      "BBCR0328      0.106373\n",
      "BBCR0329      0.066054\n",
      "BBCR0338      0.384967\n",
      "Length: 91, dtype: float32\n",
      "✓ Terminé.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# --- CONFIG ---\n",
    "# Renseigne ces 3 chemins + options. Laisse le reste par défaut.\n",
    "\n",
    "DATA_ROOT       = \"/Users/noeamar/Documents/Stanford/data/Biobank SSI\"  # dossier du dataset\n",
    "FOLD_FEATS_PATH = \"/Users/noeamar/Documents/Stanford/results_cls_24c_CyTOF_xgboost_knockoff_shap_CLS\"  # run existant avec Selected Features *.csv\n",
    "SAVE_ROOT       = \"results_CI_SSI_vf_xgb_shap_existing_notebook\"  # dossier de sortie pour CE run\n",
    "\n",
    "DATASET         = \"ssi\"               # \"ssi\" (par défaut) ou \"onset\"\n",
    "MODEL_CHOSEN    = \"xgboost\"          # pour la comparaison 'existing-fit' : \"xgboost\" | \"random_forest\" | \"logit\"\n",
    "N_SPLITS        = 100\n",
    "TEST_SIZE       = 0.2\n",
    "RANDOM_STATE    = 42\n",
    "\n",
    "# Optionnel : ajouter des combos Union/Intersect entre STABL models si présents dans FOLD_FEATS_PATH\n",
    "ADD_COMBOS      = False  # True pour générer Union/Intersect 2-à-2\n",
    "\n",
    "\n",
    "# %%\n",
    "import os\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# Dataset loaders & STABL pipeline\n",
    "from stabl.data import load_ssi, load_onset_of_labor\n",
    "from stabl.multi_omic_pipelines import multi_omic_stabl_cv_noe_test  # <- ta fonction modifiée\n",
    "\n",
    "# %%\n",
    "DATA_ROOT = Path(DATA_ROOT)\n",
    "FOLD_FEATS_PATH = Path(FOLD_FEATS_PATH)\n",
    "SAVE_ROOT = Path(SAVE_ROOT)\n",
    "SAVE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if DATASET == \"ssi\":\n",
    "    train_dict, _, y, _, _, task_type = load_ssi(str(DATA_ROOT))\n",
    "    y = y.astype(int)\n",
    "    assert set(y.unique()) <= {0, 1}, f\"Labels non binaires: {sorted(y.unique())}\"\n",
    "    cyto = train_dict[\"CyTOF\"]\n",
    "    prot = train_dict[\"Proteomics\"].copy()\n",
    "    prot.columns = [f\"PRO_{c}\" for c in prot.columns]  # évite collisions de noms\n",
    "    common = y.index\n",
    "    for df in (cyto, prot):\n",
    "        common = common.intersection(df.index)\n",
    "    y = y.loc[common]\n",
    "    X = pd.concat([cyto.loc[common], prot.loc[common]], axis=1)\n",
    "else:\n",
    "    train_dict, valid_data_dict, y, y_valid, patients_id, task_type = load_onset_of_labor(str(DATA_ROOT))\n",
    "    cyto = train_dict[\"CyTOF\"]\n",
    "    prot = train_dict[\"Proteomics\"].copy()\n",
    "    prot.columns = [f\"PRO_{c}\" for c in prot.columns]\n",
    "    common = y.index\n",
    "    for df in (cyto, prot):\n",
    "        common = common.intersection(df.index)\n",
    "    y = y.loc[common]\n",
    "    X = pd.concat([cyto.loc[common], prot.loc[common]], axis=1)\n",
    "\n",
    "print(f\"X shape: {X.shape} | y: {y.shape} | task_type: {task_type}\")\n",
    "display(X.head(2))\n",
    "display(y.value_counts())\n",
    "\n",
    "\n",
    "# %%\n",
    "# Groupes par patient (avant l'underscore)\n",
    "groups = X.index.to_series().str.split(\"_\").str[0]\n",
    "splitter = GroupShuffleSplit(n_splits=N_SPLITS, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "# Early-fusion dans un seul \"omic\"\n",
    "data_dict = {\"allstim\": X}\n",
    "\n",
    "# On propose comme base ces modèles; on filtre ceux dont les CSV existent réellement\n",
    "candidate_stabl = [\"STABL Lasso\", \"STABL ElasticNet\", \"STABL ALasso\", \"STABL XGBoost\"]\n",
    "available = []\n",
    "for m in candidate_stabl:\n",
    "    csv_path = FOLD_FEATS_PATH / \"Training CV\" / f\"Selected Features {m}.csv\"\n",
    "    if csv_path.exists():\n",
    "        available.append(m)\n",
    "    else:\n",
    "        print(f\"[WARN] Missing features file for {m}: {csv_path}\")\n",
    "\n",
    "if not available:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Aucun CSV 'Selected Features {{model}}.csv' trouvé dans {FOLD_FEATS_PATH/'Training CV'}.\\n\"\n",
    "        \"Vérifie les noms exacts de modèles et le chemin 'fold_feats_path'.\"\n",
    "    )\n",
    "\n",
    "# Optionnel : Union/Intersect 2-à-2 des modèles disponibles\n",
    "models = list(available)\n",
    "if ADD_COMBOS and len(available) >= 2:\n",
    "    sep = \" & \"\n",
    "    combos = []\n",
    "    for group in itertools.combinations(available, 2):\n",
    "        combos += [f\"Union {sep.join(group)}\", f\"Intersect {sep.join(group)}\"]\n",
    "    models += combos\n",
    "\n",
    "print(\"Models utilisés :\", models)\n",
    "\n",
    "# %%\n",
    "# Estimateurs pour le refit (utilisés par la comparaison \"existing-fit\" et par le fit de notre run)\n",
    "rf_cls = RandomForestClassifier(\n",
    "    n_estimators=600, max_depth=8, min_samples_split=2, min_samples_leaf=2,\n",
    "    max_features=\"sqrt\", ccp_alpha=1e-3, random_state=RANDOM_STATE, n_jobs=-1\n",
    ")\n",
    "xgb_cls = XGBClassifier(\n",
    "    n_estimators=800, learning_rate=0.01, max_depth=3,\n",
    "    subsample=0.6, colsample_bytree=0.5, random_state=RANDOM_STATE, n_jobs=-1,\n",
    "    eval_metric=\"logloss\", use_label_encoder=False\n",
    ")\n",
    "\n",
    "# Dictionnaire des estimateurs — seules ces clés sont requises en \"skip selection\"\n",
    "estimators = {\n",
    "    \"rf\": rf_cls,\n",
    "    \"xgb\": xgb_cls,\n",
    "    # noms attendus par cv_on_existing_feats (la fonction mappe rf/xgb → ces clés si besoin)\n",
    "    \"random_forest\": rf_cls,\n",
    "    \"xgboost\": xgb_cls,\n",
    "    \n",
    "    # placeholders (non utilisés car on skippe la sélection)\n",
    "    \"lasso\": None, \"en\": None, \"alasso\": None,\n",
    "    \"stabl_lasso\": None, \"stabl_alasso\": None, \"stabl_en\": None, \"stabl_xgb\": None,\n",
    "}\n",
    "\n",
    "print(\"Estimators ready.\")\n",
    "\n",
    "# %%\n",
    "print(\"[INFO] Starting CV with skip-selection (using existing STABL features)...\")\n",
    "preds = multi_omic_stabl_cv_noe_test(\n",
    "    data_dict       = data_dict,\n",
    "    y               = y,\n",
    "    outer_splitter  = splitter,\n",
    "    estimators      = estimators,\n",
    "    task_type       = task_type,            # \"binary\" pour SSI\n",
    "    model_chosen    = MODEL_CHOSEN,         # \"xgboost\" recommandé\n",
    "    models          = models,\n",
    "    save_path       = str(SAVE_ROOT),\n",
    "    outer_groups    = groups,\n",
    "    early_fusion    = False,\n",
    "    late_fusion     = False,\n",
    "    n_iter_lf       = 100000,\n",
    "    fold_feats_path = str(FOLD_FEATS_PATH), # là où sont les Selected Features {model}.csv\n",
    "    use_existing_feats_only = True,         # <<< SKIP la sélection; fit uniquement\n",
    ")\n",
    "print(\"✓ Terminé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e0606d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>N features</th>\n",
       "      <th>CVS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STABL Lasso</th>\n",
       "      <td>0.863 [0.769, 0.937]</td>\n",
       "      <td>0.555 [0.331, 0.788]</td>\n",
       "      <td>38.000 [30.000, 48.000]</td>\n",
       "      <td>0.250 [0.203, 0.302]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABL ElasticNet</th>\n",
       "      <td>0.732 [0.603, 0.844]</td>\n",
       "      <td>0.401 [0.220, 0.639]</td>\n",
       "      <td>165.000 [87.250, 252.750]</td>\n",
       "      <td>0.137 [0.070, 0.251]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABL ALasso</th>\n",
       "      <td>0.500 [0.500, 0.500]</td>\n",
       "      <td>0.176 [0.110, 0.253]</td>\n",
       "      <td>0.000 [0.000, 0.000]</td>\n",
       "      <td>0.000 [0.000, 0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABL XGBoost</th>\n",
       "      <td>0.932 [0.852, 0.988]</td>\n",
       "      <td>0.847 [0.684, 0.957]</td>\n",
       "      <td>8.000 [6.000, 11.000]</td>\n",
       "      <td>0.125 [0.067, 0.200]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABL Lasso (existing-fit)</th>\n",
       "      <td>0.884 [0.804, 0.953]</td>\n",
       "      <td>0.597 [0.363, 0.821]</td>\n",
       "      <td>38.000 [30.000, 48.000]</td>\n",
       "      <td>0.033 [0.027, 0.039]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABL ElasticNet (existing-fit)</th>\n",
       "      <td>0.769 [0.662, 0.865]</td>\n",
       "      <td>0.335 [0.200, 0.556]</td>\n",
       "      <td>165.000 [87.250, 252.750]</td>\n",
       "      <td>0.006 [0.005, 0.009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABL ALasso (existing-fit)</th>\n",
       "      <td>0.500 [0.500, 0.500]</td>\n",
       "      <td>0.176 [0.099, 0.253]</td>\n",
       "      <td>0.000 [0.000, 0.000]</td>\n",
       "      <td>1.000 [1.000, 1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABL XGBoost (existing-fit)</th>\n",
       "      <td>0.954 [0.893, 0.995]</td>\n",
       "      <td>0.881 [0.720, 0.979]</td>\n",
       "      <td>8.000 [6.000, 11.000]</td>\n",
       "      <td>0.108 [0.090, 0.130]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ROC AUC     Average Precision  \\\n",
       "STABL Lasso                      0.863 [0.769, 0.937]  0.555 [0.331, 0.788]   \n",
       "STABL ElasticNet                 0.732 [0.603, 0.844]  0.401 [0.220, 0.639]   \n",
       "STABL ALasso                     0.500 [0.500, 0.500]  0.176 [0.110, 0.253]   \n",
       "STABL XGBoost                    0.932 [0.852, 0.988]  0.847 [0.684, 0.957]   \n",
       "STABL Lasso (existing-fit)       0.884 [0.804, 0.953]  0.597 [0.363, 0.821]   \n",
       "STABL ElasticNet (existing-fit)  0.769 [0.662, 0.865]  0.335 [0.200, 0.556]   \n",
       "STABL ALasso (existing-fit)      0.500 [0.500, 0.500]  0.176 [0.099, 0.253]   \n",
       "STABL XGBoost (existing-fit)     0.954 [0.893, 0.995]  0.881 [0.720, 0.979]   \n",
       "\n",
       "                                                N features  \\\n",
       "STABL Lasso                        38.000 [30.000, 48.000]   \n",
       "STABL ElasticNet                 165.000 [87.250, 252.750]   \n",
       "STABL ALasso                          0.000 [0.000, 0.000]   \n",
       "STABL XGBoost                        8.000 [6.000, 11.000]   \n",
       "STABL Lasso (existing-fit)         38.000 [30.000, 48.000]   \n",
       "STABL ElasticNet (existing-fit)  165.000 [87.250, 252.750]   \n",
       "STABL ALasso (existing-fit)           0.000 [0.000, 0.000]   \n",
       "STABL XGBoost (existing-fit)         8.000 [6.000, 11.000]   \n",
       "\n",
       "                                                  CVS  \n",
       "STABL Lasso                      0.250 [0.203, 0.302]  \n",
       "STABL ElasticNet                 0.137 [0.070, 0.251]  \n",
       "STABL ALasso                     0.000 [0.000, 0.000]  \n",
       "STABL XGBoost                    0.125 [0.067, 0.200]  \n",
       "STABL Lasso (existing-fit)       0.033 [0.027, 0.039]  \n",
       "STABL ElasticNet (existing-fit)  0.006 [0.005, 0.009]  \n",
       "STABL ALasso (existing-fit)      1.000 [1.000, 1.000]  \n",
       "STABL XGBoost (existing-fit)     0.108 [0.090, 0.130]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "scores_csv = SAVE_ROOT / \"Summary\" / \"Scores training CV.csv\"\n",
    "if scores_csv.exists():\n",
    "    scores_df = pd.read_csv(scores_csv, index_col=0)\n",
    "    display(scores_df)\n",
    "else:\n",
    "    print(f\"[WARN] Fichier scores introuvable: {scores_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "91980ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    folds     mean  median  \\\n",
      "file                                                                         \n",
      "Selected Features Intersect STABL XGBoost & STA...     25  1846.00  1846.0   \n",
      "Selected Features STABL ALasso.csv                     25    26.56    27.0   \n",
      "Selected Features STABL XGBoost.csv                    25    14.36    13.0   \n",
      "Selected Features Union STABL XGBoost & STABL A...     25    36.52    36.0   \n",
      "\n",
      "                                                      std   min   max     25%  \\\n",
      "file                                                                            \n",
      "Selected Features Intersect STABL XGBoost & STA...   0.00  1846  1846  1846.0   \n",
      "Selected Features STABL ALasso.csv                  11.69     8    50    16.0   \n",
      "Selected Features STABL XGBoost.csv                  6.99     2    32    10.0   \n",
      "Selected Features Union STABL XGBoost & STABL A...  11.37    20    59    28.0   \n",
      "\n",
      "                                                       75%  unique_feats  \n",
      "file                                                                      \n",
      "Selected Features Intersect STABL XGBoost & STA...  1846.0          1846  \n",
      "Selected Features STABL ALasso.csv                    38.0           148  \n",
      "Selected Features STABL XGBoost.csv                   18.0            95  \n",
      "Selected Features Union STABL XGBoost & STABL A...    46.0           198  \n"
     ]
    }
   ],
   "source": [
    "import glob, ast, statistics, os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 1) dossier contenant \"Training CV/Selected Features *.csv\"\n",
    "ROOT = Path(\"/Users/noeamar/Documents/Stanford/results_test_SSI\")   # ← à adapter\n",
    "CSV_PATTERN = ROOT / \"Training CV\" / \"Selected Features *.csv\"\n",
    "\n",
    "def to_list(cell):\n",
    "    \"Transforme une cellule en liste de features (ou None).\"\n",
    "    if isinstance(cell, str):\n",
    "        try:\n",
    "            return list(ast.literal_eval(cell))\n",
    "        except Exception:\n",
    "            return None\n",
    "    elif isinstance(cell, (list, tuple, set)):\n",
    "        return list(cell)\n",
    "    return None\n",
    "\n",
    "def count_feats(cell):\n",
    "    \"Renvoie le nombre de features dans la cellule.\"\n",
    "    if isinstance(cell, (int, float)):\n",
    "        return int(cell)\n",
    "    lst = to_list(cell)\n",
    "    return len(lst) if lst is not None else None\n",
    "\n",
    "summary = []\n",
    "\n",
    "for csv in glob.glob(str(CSV_PATTERN)):\n",
    "    df = pd.read_csv(csv, index_col=0)\n",
    "\n",
    "    # 1) Compte par fold\n",
    "    if \"Fold nb of features\" in df.columns:\n",
    "        counts = df[\"Fold nb of features\"].astype(int)\n",
    "    elif \"Fold #features\" in df.columns:\n",
    "        counts = df[\"Fold #features\"].astype(int)\n",
    "    else:  # on recompte à partir de la colonne listes\n",
    "        counts = df.iloc[:, 0].apply(count_feats)\n",
    "\n",
    "    counts = counts.dropna().astype(int)\n",
    "\n",
    "    # 2) Union des features sur tous les folds\n",
    "    if \"Fold selected features\" in df.columns:\n",
    "        all_feats = set().union(*df[\"Fold selected features\"].apply(to_list).dropna())\n",
    "    else:\n",
    "        # si la colonne n'existe pas, on ne peut pas calculer\n",
    "        all_feats = set()\n",
    "\n",
    "    stats = {\n",
    "        \"file\":           os.path.basename(csv),\n",
    "        \"folds\":          len(counts),\n",
    "        \"mean\":           counts.mean(),\n",
    "        \"median\":         counts.median(),\n",
    "        \"std\":            counts.std(ddof=1),\n",
    "        \"min\":            counts.min(),\n",
    "        \"max\":            counts.max(),\n",
    "        \"25%\":            counts.quantile(0.25),\n",
    "        \"75%\":            counts.quantile(0.75),\n",
    "        \"unique_feats\":   len(all_feats) if all_feats else \"n/a\",\n",
    "    }\n",
    "    summary.append(stats)\n",
    "\n",
    "summary_df = (\n",
    "    pd.DataFrame(summary)\n",
    "      .set_index(\"file\")\n",
    "      .round(2)\n",
    "      .sort_index()\n",
    ")\n",
    "print(summary_df)\n",
    "\n",
    "# (option) sauvegarder\n",
    "summary_df.to_csv(ROOT / \"summary_feature_counts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c9a406fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Omic: Proteomics]\n",
      "  Train cols: 1463 | Val cols: 1420 | Common: 1420\n",
      "  → Only in TRAIN (43): ['arid4b', 'atp6v1f', 'cetn2', 'chek2', 'clstn1', 'cope', 'dctn6', 'ece1', 'gbp4', 'gdnf'] ...\n",
      "  → Only in VAL   (0): []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def _to_dict(df_or_dict):\n",
    "    \"\"\"Accepte DataFrame ou dict[str, DataFrame] → dict normalisé.\"\"\"\n",
    "    if isinstance(df_or_dict, pd.DataFrame):\n",
    "        return {\"all\": df_or_dict}\n",
    "    if isinstance(df_or_dict, dict):\n",
    "        return df_or_dict\n",
    "    raise TypeError(\"Expected DataFrame or dict[str, DataFrame].\")\n",
    "\n",
    "def compare_train_val_features(X_train, X_val, strip=True, lower=False, export_csv=None):\n",
    "    \"\"\"\n",
    "    Compare les colonnes (features) entre train et validation.\n",
    "    - X_train, X_val : DataFrame ou dict[str, DataFrame]\n",
    "    - strip : .strip() sur les noms de colonnes\n",
    "    - lower : .lower() sur les noms de colonnes\n",
    "    - export_csv : chemin dossier pour exporter des CSV par omic (optionnel)\n",
    "    Retourne un dict avec pour chaque omic : only_in_train / only_in_val / common_count.\n",
    "    \"\"\"\n",
    "    tr = _to_dict(X_train)\n",
    "    va = _to_dict(X_val)\n",
    "\n",
    "    omic_names = sorted(set(tr.keys()) | set(va.keys()))\n",
    "    results = {}\n",
    "\n",
    "    if export_csv:\n",
    "        Path(export_csv).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for omic in omic_names:\n",
    "        df_tr = tr.get(omic)\n",
    "        df_va = va.get(omic)\n",
    "\n",
    "        if df_tr is None or df_va is None:\n",
    "            results[omic] = {\n",
    "                \"status\": \"missing_table\",\n",
    "                \"in_train\": df_tr is not None,\n",
    "                \"in_val\": df_va is not None\n",
    "            }\n",
    "            print(f\"[WARN] Omic '{omic}': présent dans train={df_tr is not None}, val={df_va is not None}\")\n",
    "            continue\n",
    "\n",
    "        def clean(cols):\n",
    "            s = pd.Index(cols)\n",
    "            if strip:\n",
    "                s = s.map(lambda c: c.strip() if isinstance(c, str) else c)\n",
    "            if lower:\n",
    "                s = s.map(lambda c: c.lower() if isinstance(c, str) else c)\n",
    "            return pd.Index(s)\n",
    "\n",
    "        cols_tr = set(clean(df_tr.columns))\n",
    "        cols_va = set(clean(df_va.columns))\n",
    "\n",
    "        only_tr = sorted(cols_tr - cols_va)\n",
    "        only_va = sorted(cols_va - cols_tr)\n",
    "        common = cols_tr & cols_va\n",
    "\n",
    "        results[omic] = {\n",
    "            \"status\": \"ok\",\n",
    "            \"only_in_train\": only_tr,\n",
    "            \"only_in_val\": only_va,\n",
    "            \"common_count\": len(common),\n",
    "            \"train_count\": len(cols_tr),\n",
    "            \"val_count\": len(cols_va),\n",
    "        }\n",
    "\n",
    "        print(f\"\\n[Omic: {omic}]\")\n",
    "        print(f\"  Train cols: {len(cols_tr)} | Val cols: {len(cols_va)} | Common: {len(common)}\")\n",
    "        print(f\"  → Only in TRAIN ({len(only_tr)}): {only_tr[:10]}{' ...' if len(only_tr)>10 else ''}\")\n",
    "        print(f\"  → Only in VAL   ({len(only_va)}): {only_va[:10]}{' ...' if len(only_va)>10 else ''}\")\n",
    "\n",
    "        if export_csv:\n",
    "            pd.Series(only_tr, name=\"only_in_train\").to_csv(Path(export_csv)/f\"{omic}_only_in_train.csv\", index=False)\n",
    "            pd.Series(only_va, name=\"only_in_val\").to_csv(Path(export_csv)/f\"{omic}_only_in_val.csv\", index=False)\n",
    "\n",
    "    return results\n",
    "\n",
    "X_train, X_valid, y_train, y_valid, ids, task_type = load_covid_19(\"data/COVID-19\")\n",
    "results = compare_train_val_features(\n",
    "    X_train, X_valid,\n",
    "    strip=True, lower=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Common_venv (3.9.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
